{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16fzyosnUlUPam2mayC798poS7uE_QTeV",
      "authorship_tag": "ABX9TyPsrvbh+8wu1t2ix2EfilRr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JairEsc/Mat_Apl_2/blob/main/ML_T5_traductor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargamos de \"manythings.org\" el dataset spa-eng.zip. Con pares de palabras en inglés-español."
      ],
      "metadata": {
        "id": "d1RaO8pXWUn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCykm83QMIfI",
        "outputId": "1d5b65aa-aeac-4887-a1ed-6ec3ab455f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-03 00:22:43--  http://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5336731 (5.1M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip.1’\n",
            "\n",
            "spa-eng.zip.1       100%[===================>]   5.09M  2.82MB/s    in 1.8s    \n",
            "\n",
            "2022-12-03 00:22:45 (2.82 MB/s) - ‘spa-eng.zip.1’ saved [5336731/5336731]\n",
            "\n",
            "Archive:  spa-eng.zip\n",
            "replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "replace spa.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: no\n",
            "total 30752\n",
            "-rw-r--r-- 1 root root     1441 Sep  6 03:10 _about.txt\n",
            "-rw-r--r-- 1 root root    55069 Dec  3 00:09 accuracy_model.png\n",
            "-rw-r--r-- 1 root root    39767 Dec  3 00:09 decoder_model.png\n",
            "drwx------ 5 root root     4096 Dec  3 00:05 drive\n",
            "-rw-r--r-- 1 root root    26161 Dec  3 00:06 encoder_model.png\n",
            "drwxr-xr-x 1 root root     4096 Dec  1 20:08 sample_data\n",
            "-rw-r--r-- 1 root root  5336731 Sep  5 23:54 spa-eng.zip\n",
            "-rw-r--r-- 1 root root  5336731 Sep  5 23:54 spa-eng.zip.1\n",
            "-rw-r--r-- 1 root root 20675392 Sep  6 03:10 spa.txt\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.manythings.org/anki/spa-eng.zip\n",
        "!unzip spa-eng.zip\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "SENTENCE_COUNT = 1000# Para el LSTM, que sean poquitas\n",
        "input_sentences = []\n",
        "input_translated_sentences = []\n",
        "output_translated_sentences = []\n",
        "sentences_file_path = '/content/spa.txt'#Cargamos el dataset\n",
        "count = 0\n",
        "for line in open(sentences_file_path, encoding='utf-8'):\n",
        "    if count < SENTENCE_COUNT:\n",
        "        if '\\t' in line:\n",
        "            line = re.sub(r'[^\\w\\s]','', line)# Primer valor: English,  \n",
        "            line_values = line.rstrip().split('\\t')\n",
        "            input_sentences.append(line_values[0])\n",
        "\n",
        "            #Tokens de incio y final\n",
        "            input_translated_sentence = '走 ' + line_values[1]#Segundo: Frase en español\n",
        "            output_translated_sentence = line_values[1] + ' 停'\n",
        "\n",
        "            input_translated_sentences.append(input_translated_sentence)\n",
        "            output_translated_sentences.append(output_translated_sentence)\n",
        "            count += 1\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "HCHtlhkIMK1e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "VOCABULARY_SIZE = 10000 #máximo vocalubario posible \n",
        "# Tokenizamos\n",
        "input_tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "# Convertimos a secuencias \n",
        "input_sequences = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "#Diccionario de palabras del input\n",
        "word_index_dict = input_tokenizer.word_index\n",
        "max_input_length = max(len(seq) for seq in input_sequences)"
      ],
      "metadata": {
        "id": "u23yo0trMaKS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Todo el proceso anterior pero para el output.\n",
        "output_tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
        "output_tokenizer.fit_on_texts(input_translated_sentences + output_translated_sentences)\n",
        "input_translated_sequences = output_tokenizer.texts_to_sequences(input_translated_sentences)\n",
        "output_translated_sequences = output_tokenizer.texts_to_sequences(output_translated_sentences)\n",
        "translated_word_index_dict = output_tokenizer.word_index\n",
        "max_output_length = max([len(seq) for seq in output_translated_sequences])"
      ],
      "metadata": {
        "id": "yJwSgu_0Mgzk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ],
      "metadata": {
        "id": "8Z_gRtFMXowW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_sequences, maxlen=max_input_length)\n",
        "decoder_input_sequences = pad_sequences(input_translated_sequences, maxlen=max_output_length, padding='post')\n",
        "decoder_output_sequences = pad_sequences(output_translated_sequences, maxlen=max_output_length, padding='post')"
      ],
      "metadata": {
        "id": "Igj9nek0Mku0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos en Drive el **glove.6B.300d**, el embedding del diccionario en inglés.\n",
        "\n",
        "Y creamos el embedding word 2 vec."
      ],
      "metadata": {
        "id": "mul8HTRoXs8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import array, asarray, zeros\n",
        "embeddings_file_path = '/content/drive/MyDrive/glove.6B.300d.txt'\n",
        "embeddings_dict_w2v = dict()\n",
        "w2v_file = open(embeddings_file_path)\n",
        "\n",
        "for line in w2v_file:\n",
        "    records = line.split() # Turn into array with word on first position and embeddings as rest of line.\n",
        "    word = records[0]\n",
        "    vector_dim = asarray(records[1:], dtype='float32') # Take rest of embeddings out.\n",
        "    embeddings_dict_w2v[word] = vector_dim # Add to embe"
      ],
      "metadata": {
        "id": "XzzGwPeoM904"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 300 #tamaño de los embeddings\n",
        "word_count = VOCABULARY_SIZE\n",
        "embeddings_matrix_w2v = zeros((word_count, EMBEDDING_SIZE)) \n",
        "for word, index in word_index_dict.items():\n",
        "    # Attempts to get word embeddings for specific word.\n",
        "    embeddings_vector = embeddings_dict_w2v.get(word)\n",
        "    if embeddings_vector is not None:\n",
        "        embeddings_matrix_w2v[index] = embeddings_vector"
      ],
      "metadata": {
        "id": "jCsOVisHPZu6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "twc = len(translated_word_index_dict) + 1\n",
        "decoder_targets_OHE = to_categorical(decoder_output_sequences, num_classes=twc)"
      ],
      "metadata": {
        "id": "6clJ8-E6Pods"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding, Dropout, GlobalMaxPooling1D \n",
        "from keras.models import Model\n",
        "from IPython.display import Image\n",
        "from keras.utils import plot_model\n",
        "\n",
        "# Capa del input.\n",
        "encoder_input = Input(shape=(max_input_length,), name='EncoderInput')\n",
        "\n",
        "# Se conecta el input con la capa de embeddings\n",
        "encoder_input_x = Embedding(word_count,\n",
        "                          EMBEDDING_SIZE,\n",
        "                          weights=[embeddings_matrix_w2v],\n",
        "                          input_length=max_input_length,\n",
        "                          name='EncoderEmbeddingLayer')(encoder_input)\n",
        "\n",
        "# El output del encoder y los estados h/c se extraen para usarse en el decoder.\n",
        "encoder_output, h, c = LSTM(1024, \n",
        "                            return_state=True,\n",
        "                            name='EncoderLSTM')(encoder_input_x)\n",
        "encoder_states = [h, c]"
      ],
      "metadata": {
        "id": "NG0w1UWjPtKM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el modelo **encoder**"
      ],
      "metadata": {
        "id": "ErCrmcNxZZX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_input, encoder_states)"
      ],
      "metadata": {
        "id": "NgTYxha2PzuT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se repite el proceso para definir el **decoder**"
      ],
      "metadata": {
        "id": "IvZxjon2ZeQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SBW-vectors-300-min5.txt** es el embbeding en español."
      ],
      "metadata": {
        "id": "Oenk6rPdZiwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import array, asarray, zeros\n",
        "embeddings_file_path = '/content/drive/MyDrive/SBW-vectors-300-min5.txt'\n",
        "embeddings_dict = dict()\n",
        "glove_file = open(embeddings_file_path)\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split() # Turn into array with word on first position and embeddings as rest of line.\n",
        "    word = records[0]\n",
        "    vector_dim = asarray(records[1:], dtype='float32') # Take rest of embeddings out.\n",
        "    embeddings_dict[word] = vector_dim # Add to embeddings_dict as word:embeddings."
      ],
      "metadata": {
        "id": "FiPf0_APQJCT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 300\n",
        "word_count = min(VOCABULARY_SIZE, twc)\n",
        "embeddings_matrix = zeros((twc, EMBEDDING_SIZE)) \n",
        "for word, index in translated_word_index_dict.items():\n",
        "    # Attempts to get word embeddings for specific word.\n",
        "    embeddings_vector = embeddings_dict.get(word)\n",
        "    if embeddings_vector is not None:\n",
        "        embeddings_matrix[index] = embeddings_vector"
      ],
      "metadata": {
        "id": "p5J1GtSrTohy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición del encoder:"
      ],
      "metadata": {
        "id": "eTX342yDZ3kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# La capa de input/embeddings, ahora se carga la capa de embeddings inicializada con GloVe.\n",
        "decoder_input = Input(shape=(max_output_length,), name='DecoderInput')\n",
        "decoder_embedding = Embedding(twc, EMBEDDING_SIZE, \n",
        "                            weights=[embeddings_matrix],\n",
        "                          input_length=twc, name='DecoderEmbeddingLayer')\n",
        "\n",
        "# La capa de input se conecta con la de embeddings \n",
        "decoder_input_x = decoder_embedding(decoder_input)\n",
        "\n",
        "# El decoder LSTM se crea y se conecta con la capa de decoder_input \n",
        "decoder_LSTM = LSTM(1024, return_state=True, return_sequences=True, name='DecoderLSTM')\n",
        "decoder_output, _, _ = decoder_LSTM(decoder_input_x, initial_state=encoder_states)\n",
        "\n",
        "# Se pasa el output por dos capas densas para poder hacer las predicciones. \n",
        "decoder_dense = Dense(1024, activation='relu', name='DenseLayer') \n",
        "decoder_dense_softmax = Dense(twc, activation='softmax', name='DenseSoftmaxLayer')\n",
        "\n",
        "decoder_output = decoder_dense(decoder_output)\n",
        "decoder_output = decoder_dense_softmax(decoder_output)"
      ],
      "metadata": {
        "id": "RaV1YkHUTwvM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se generan las capas de h/c.\n",
        "decoder_state_input_h = Input(shape=(1024,), name='InputHStep')\n",
        "decoder_state_input_c = Input(shape=(1024,), name='InputCStep')\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "#el decoder debe aceptar una sola palabra para la capa de input al recorrer toda la oración.\n",
        "decoder_input_step = Input(shape=(1,), name='DecoderInputStep')\n",
        "decoder_input_x_step = decoder_embedding(decoder_input_step)\n",
        "decoder_output_step, h, c = decoder_LSTM(decoder_input_x_step, initial_state=decoder_states_inputs)\n",
        "\n",
        "# Estados finales en un array \n",
        "decoder_states = [h, c]\n",
        "\n",
        "\n",
        "#El output del decor se pasa por dos capas densas\n",
        "decoder_output_step = decoder_dense(decoder_output_step)\n",
        "decoder_output_step = decoder_dense_softmax(decoder_output_step)\n",
        "\n",
        "# Modelo decoder\n",
        "decoder_model = Model(\n",
        "    [decoder_input_step] + decoder_states_inputs, # initial input step AND initial h/c layers \n",
        "    [decoder_output_step] + decoder_states # output input step AND output h/c from decoder LSTM \n",
        ")"
      ],
      "metadata": {
        "id": "Nrf7AJvbT44I"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasta ahora ya se tiene el encoder-decoder. Después se define el modelo de precisión, recibe encoder, decoder y obtenemos un decoder de salida."
      ],
      "metadata": {
        "id": "xLqUeo6WaCPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "accuracy_model = Model([encoder_input, decoder_input], decoder_output)\n",
        "accuracy_model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "pQ4ooRSAT79t"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo entrenamos con 10 epocas y batch de 20, también le damos $10\\%$ de datos para validación."
      ],
      "metadata": {
        "id": "6YnYONmuaTYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = accuracy_model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets_OHE,\n",
        "    batch_size=20,\n",
        "    epochs=20,\n",
        "    validation_split=0.1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2m794B6UWWz",
        "outputId": "2eed8553-7438-42c7-80c0-a46200d9f263"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "45/45 [==============================] - 5s 43ms/step - loss: 0.1680 - accuracy: 0.9190 - val_loss: 5.7855 - val_accuracy: 0.6929\n",
            "Epoch 2/20\n",
            "45/45 [==============================] - 1s 21ms/step - loss: 0.1488 - accuracy: 0.9206 - val_loss: 4.9296 - val_accuracy: 0.6986\n",
            "Epoch 3/20\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.1458 - accuracy: 0.9241 - val_loss: 5.0062 - val_accuracy: 0.6957\n",
            "Epoch 4/20\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1449 - accuracy: 0.9183 - val_loss: 5.7825 - val_accuracy: 0.7029\n",
            "Epoch 5/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1490 - accuracy: 0.9216 - val_loss: 4.8511 - val_accuracy: 0.6971\n",
            "Epoch 6/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1451 - accuracy: 0.9202 - val_loss: 5.1132 - val_accuracy: 0.6971\n",
            "Epoch 7/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1431 - accuracy: 0.9208 - val_loss: 5.0785 - val_accuracy: 0.6729\n",
            "Epoch 8/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1428 - accuracy: 0.9210 - val_loss: 5.2751 - val_accuracy: 0.6814\n",
            "Epoch 9/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1390 - accuracy: 0.9221 - val_loss: 5.7229 - val_accuracy: 0.6857\n",
            "Epoch 10/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1414 - accuracy: 0.9222 - val_loss: 5.6746 - val_accuracy: 0.6857\n",
            "Epoch 11/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1412 - accuracy: 0.9221 - val_loss: 5.9490 - val_accuracy: 0.6857\n",
            "Epoch 12/20\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1431 - accuracy: 0.9225 - val_loss: 5.6197 - val_accuracy: 0.6843\n",
            "Epoch 13/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1413 - accuracy: 0.9190 - val_loss: 5.5391 - val_accuracy: 0.6900\n",
            "Epoch 14/20\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1389 - accuracy: 0.9197 - val_loss: 5.9180 - val_accuracy: 0.6829\n",
            "Epoch 15/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1388 - accuracy: 0.9211 - val_loss: 5.5629 - val_accuracy: 0.6786\n",
            "Epoch 16/20\n",
            "45/45 [==============================] - 1s 17ms/step - loss: 0.1367 - accuracy: 0.9221 - val_loss: 5.7931 - val_accuracy: 0.6843\n",
            "Epoch 17/20\n",
            "45/45 [==============================] - 1s 21ms/step - loss: 0.1367 - accuracy: 0.9211 - val_loss: 5.6626 - val_accuracy: 0.6786\n",
            "Epoch 18/20\n",
            "45/45 [==============================] - 1s 20ms/step - loss: 0.1361 - accuracy: 0.9211 - val_loss: 5.8385 - val_accuracy: 0.6814\n",
            "Epoch 19/20\n",
            "45/45 [==============================] - 1s 18ms/step - loss: 0.1362 - accuracy: 0.9214 - val_loss: 6.1344 - val_accuracy: 0.6671\n",
            "Epoch 20/20\n",
            "45/45 [==============================] - 1s 16ms/step - loss: 0.1366 - accuracy: 0.9210 - val_loss: 5.7557 - val_accuracy: 0.6714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se llega a $92\\%$ de precisión en los datos de entrenamiento y $70\\%$ en los de validación."
      ],
      "metadata": {
        "id": "mCp90-y_bKBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_word_dict = {i:w for w,i in word_index_dict.items()}\n",
        "index_translated_word_dict = {i:w for w,i in translated_word_index_dict.items()}"
      ],
      "metadata": {
        "id": "IX7_4PtRUgVt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(input_seq):\n",
        "    # Retorna los valores inciales de h/c que se generan con la oración input\n",
        "    states_values = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Regresa el token de inicio e inicia el target_seq \n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = translated_word_index_dict['走']\n",
        "\n",
        "    # Asigna el token del final a una variable y se para el for cuando se alcanza este valor\n",
        "    eos = translated_word_index_dict['停']\n",
        "\n",
        "    # Cada palabra del output se agrega a esta lista \n",
        "    output_sentence = []\n",
        "\n",
        "    # Recorrer indefinidamente hasta que alcance el máximo largo de la oración\n",
        "    for _ in range(max_output_length):\n",
        "        # Retorna los estados predecidos \n",
        "        output_seq, h, c = decoder_model.predict([target_seq] + states_values)\n",
        "\n",
        "        # Regresa el indice con mayor valor del arreglo del softmax \n",
        "        idx = np.argmax(output_seq[0, 0])\n",
        "        if eos == idx: # si el indice es igual al del token de final se para el proceso\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "\n",
        "        if idx > 0: # si el indice no es padding\n",
        "            word = index_translated_word_dict[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "\n",
        "        target_seq[0, 0] = idx\n",
        "        states_values = [h, c]\n",
        "\n",
        "    # Retorna la oración output como un string.\n",
        "    return ' '.join(output_sentence)"
      ],
      "metadata": {
        "id": "4BYBuKDJUjoT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tomamos 3 frases al azar para mostrar el desempeño. Teniendo $92\\%$ de precisión nos hace esperar muy buenos resultados.*texto en cursiva*"
      ],
      "metadata": {
        "id": "iS7-COVFbzqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 1\n",
        "for _ in range(3):\n",
        "    print(f'Translation {count}: ')\n",
        "    i = np.random.choice(len(input_sentences))\n",
        "    input_seq = encoder_input_sequences[i:i+1]\n",
        "    translation = translate_sentence(input_seq)\n",
        "    print('Input:', input_sentences[i])\n",
        "    print('Response:', translation)\n",
        "    print('')\n",
        "    count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxaqgi4HUmtB",
        "outputId": "a60b5521-c8d0-4a42-8aaa-bb4ac00d57f1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation 1: \n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Input: Move over\n",
            "Response: veníos\n",
            "\n",
            "Translation 2: \n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Input: Hes a DJ\n",
            "Response: él es dj\n",
            "\n",
            "Translation 3: \n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Input: Im happy\n",
            "Response: estoy feliz\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En efecto, el desempeño es bueno."
      ],
      "metadata": {
        "id": "VJOYk_7ab_E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence(sentence):\n",
        "    sentence = re.sub(r'[^\\w\\s]','', sentence)\n",
        "    sentence_array = sentence.rstrip().lower().split(' ')\n",
        "    sentence_sequence = [word_index_dict[word] for word in sentence_array if word in word_index_dict.keys()]\n",
        "    sentence_sequence = pad_sequences([sentence_sequence], maxlen=max_input_length)\n",
        "    return sentence_sequence"
      ],
      "metadata": {
        "id": "ezxTK6YaUpFe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicción con frases nuevas:"
      ],
      "metadata": {
        "id": "GI-57hnPcm7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_sentences = [\n",
        "    'This was really hard',\n",
        "    'I did understood something',\n",
        "    'Im tired of working',             \n",
        "]\n",
        "\n",
        "custom_sequences = []\n",
        "\n",
        "for custom_sentence in custom_sentences:\n",
        "    sequence = prepare_sequence(custom_sentence)\n",
        "    custom_sequences.append(sequence)\n",
        "\n",
        "for i, custom_sequence in enumerate(custom_sequences):\n",
        "    translation = translate_sentence(custom_sequence)\n",
        "\n",
        "    print('Input:', custom_sentences[i])\n",
        "    print('Response:', translation)\n",
        "    print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6SbsjNiUsil",
        "outputId": "76ad87f1-0dc8-49e8-cbe1-1f20ab9a894d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Input: This was really hard\n",
            "Response: estoy duro\n",
            "\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Input: I did understood something\n",
            "Response: yo lo sé\n",
            "\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Input: Im tired of working\n",
            "Response: estoy lleno\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusión. \n",
        "\n",
        "Se utilizan embeddings de inglés y español predefinidos para un encoder-decoder de frases a nivel palabras. \n",
        "Se obtiene buena precisión en los datos de entrenamiento ($90\\%$) y no tan buenos en los datos de validación ($70\\%$), lo que podría indicar que nuestra red se memoriza las frases del diccionario que se le pasa. \n",
        "\n",
        "Se hacen predicciones de frases que no necesariamente se encuentran en la base de datos y los resultados son malos, lo que parece confirmar que nuestra red se memorizó los datos de entrenamiento."
      ],
      "metadata": {
        "id": "pRfaftRTddPG"
      }
    }
  ]
}