{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFeIdAo+RzyND+TTx5gY3o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JairEsc/Mat_Apl_2/blob/main/Biomate_NN_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IklufuqUwcpX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estructura de los datos."
      ],
      "metadata": {
        "id": "MpFOG--QxVDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consideramos un caso general, una base con datos de frecuencias de especies, cada observación de dimensión $k$, y supongamos que tenemos $n$ observaciones.\n",
        "\n",
        "El output busca ser la clasificación en una de $d$ categorías, definidas ya sea por ciudad o localización-clima (pero de un sólo tipo).\n"
      ],
      "metadata": {
        "id": "GznOeGsWxYfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos de ejemplo"
      ],
      "metadata": {
        "id": "NrrajEuRytBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"Dataset_w_tags.csv\")\n",
        "df.head()\n",
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)###El ajuste depende de este shuffle*****"
      ],
      "metadata": {
        "id": "30vL3CcXxUUE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zSWbW5vz3PI",
        "outputId": "82494b3b-beea-489e-b752-6559969167da"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 513)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se tienen 237 observaciones, cada una es una muestra en una \"localización\".\n",
        "Por renglón, se tienen frecuencias de \"bichos\" de 510 \"dominant taxa\".\n",
        "\n",
        "En este caso, $k=510$, $n=237$."
      ],
      "metadata": {
        "id": "20gcA30JzhrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytags=df['Tag']\n",
        "print(ytags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I84se6Sw-Mdt",
        "outputId": "0108c166-38d7-4ac5-b07d-bf32db6a9d51"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219    Temperate forests_0\n",
            "144       Dry grasslands_3\n",
            "148               Boreal_5\n",
            "233         Cold forests_3\n",
            "97           Dry forests_0\n",
            "              ...         \n",
            "55          Cold forests_6\n",
            "89           Dry forests_0\n",
            "80           Dry forests_0\n",
            "61          Cold forests_6\n",
            "222    Temperate forests_0\n",
            "Name: Tag, Length: 237, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n1a5c4A1-5_",
        "outputId": "ff69fa44-f9bb-4db4-95e6-f78ca43d95af"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "219    Temperate forests_0\n",
              "144       Dry grasslands_3\n",
              "148               Boreal_5\n",
              "233         Cold forests_3\n",
              "97           Dry forests_0\n",
              "              ...         \n",
              "55          Cold forests_6\n",
              "89           Dry forests_0\n",
              "80           Dry forests_0\n",
              "61          Cold forests_6\n",
              "222    Temperate forests_0\n",
              "Name: Tag, Length: 237, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "_,idx = np.unique(ytags,return_inverse=True)"
      ],
      "metadata": {
        "id": "E6fYhQo7BNGu"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados los datos con su respectiva clasificación. (En el ejemplo $d=12$)\n",
        "\n",
        "\n",
        "Lamentablemente los datos tienen clases sub-representadas"
      ],
      "metadata": {
        "id": "6mk01dMO3f12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(idx,bins=37)\n",
        "plt.show()#Mala representatividad de clases."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "QVlF0yPp2YOY",
        "outputId": "20238eee-0d75-4907-9fc6-e18e04bed12b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición del modelo."
      ],
      "metadata": {
        "id": "fOP0O0MV3pmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partición de datos"
      ],
      "metadata": {
        "id": "JydTuMKmF2t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "X_total=df.drop(columns=['Tag','Dominant_taxa_ID/ID_Environmental'])\n",
        "Y_total=to_categorical(idx)"
      ],
      "metadata": {
        "id": "rrhUqdDM4cVL"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_total[0:200]\n",
        "Y_train=Y_total[0:200]"
      ],
      "metadata": {
        "id": "O2iYyd0mGEIW"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "k,n=X_train.shape\n",
        "n=n#-indice, -tag\n",
        "print(k,n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueLx_pz_GAe4",
        "outputId": "c0b9cc66-c674-471a-b4da-9fa97cb64763"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (n,)#=n\n",
        "output_shape=len(np.unique(ytags))"
      ],
      "metadata": {
        "id": "RrB-qCBDB1LX"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "from keras import models\n"
      ],
      "metadata": {
        "id": "XVlSzWd23fCO"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capas, neuronas, funciones de activación, loss."
      ],
      "metadata": {
        "id": "rlhbU_ZwNh_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(input_shape=(n,), name='Input_Layer'))#Obligatoria\n",
        "model.add(layers.Dense(10, activation='relu'))# Numero de capas ocultas: Opcional\n",
        "model.add(layers.Dense(10, activation='relu'))# Numero de neuronas en cada capa: Opcional\n",
        "model.add(layers.Dense(37, activation='Softmax', name='Output_Layer'))#Obligatoria\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "import time\n",
        "tic = time.time()\n",
        "\n",
        "model.fit(x = X_train, \n",
        "           y = Y_train, \n",
        "          validation_data=[X_total[200:], Y_total[200:]],\n",
        "          batch_size=50,\n",
        "           epochs=200,\n",
        "           verbose=2,shuffle=True)\n",
        "\n",
        "print('seconds=', time.time()-tic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ntg-BtqwqpQ",
        "outputId": "40b2e755-3312-445b-8b31-26395dcc408c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                5120      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 37)                407       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,637\n",
            "Trainable params: 5,637\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "4/4 - 1s - loss: 10.6835 - accuracy: 0.0200 - val_loss: 7.5658 - val_accuracy: 0.0270 - 1s/epoch - 267ms/step\n",
            "Epoch 2/200\n",
            "4/4 - 0s - loss: 6.3449 - accuracy: 0.0300 - val_loss: 5.7665 - val_accuracy: 0.0000e+00 - 142ms/epoch - 36ms/step\n",
            "Epoch 3/200\n",
            "4/4 - 0s - loss: 4.7748 - accuracy: 0.0200 - val_loss: 4.9277 - val_accuracy: 0.0000e+00 - 160ms/epoch - 40ms/step\n",
            "Epoch 4/200\n",
            "4/4 - 0s - loss: 4.2081 - accuracy: 0.0250 - val_loss: 4.4308 - val_accuracy: 0.0000e+00 - 164ms/epoch - 41ms/step\n",
            "Epoch 5/200\n",
            "4/4 - 0s - loss: 3.9237 - accuracy: 0.0300 - val_loss: 4.0726 - val_accuracy: 0.0270 - 106ms/epoch - 26ms/step\n",
            "Epoch 6/200\n",
            "4/4 - 0s - loss: 3.7431 - accuracy: 0.0550 - val_loss: 3.8585 - val_accuracy: 0.0541 - 43ms/epoch - 11ms/step\n",
            "Epoch 7/200\n",
            "4/4 - 0s - loss: 3.6534 - accuracy: 0.1000 - val_loss: 3.7185 - val_accuracy: 0.0811 - 92ms/epoch - 23ms/step\n",
            "Epoch 8/200\n",
            "4/4 - 0s - loss: 3.5872 - accuracy: 0.1050 - val_loss: 3.6588 - val_accuracy: 0.1081 - 83ms/epoch - 21ms/step\n",
            "Epoch 9/200\n",
            "4/4 - 0s - loss: 3.5200 - accuracy: 0.1100 - val_loss: 3.6212 - val_accuracy: 0.1351 - 29ms/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "4/4 - 0s - loss: 3.4717 - accuracy: 0.1250 - val_loss: 3.5785 - val_accuracy: 0.1622 - 32ms/epoch - 8ms/step\n",
            "Epoch 11/200\n",
            "4/4 - 0s - loss: 3.4307 - accuracy: 0.1450 - val_loss: 3.5380 - val_accuracy: 0.1892 - 32ms/epoch - 8ms/step\n",
            "Epoch 12/200\n",
            "4/4 - 0s - loss: 3.3928 - accuracy: 0.1750 - val_loss: 3.5051 - val_accuracy: 0.2162 - 29ms/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "4/4 - 0s - loss: 3.3627 - accuracy: 0.2100 - val_loss: 3.4919 - val_accuracy: 0.2432 - 30ms/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "4/4 - 0s - loss: 3.3349 - accuracy: 0.2150 - val_loss: 3.4722 - val_accuracy: 0.2162 - 31ms/epoch - 8ms/step\n",
            "Epoch 15/200\n",
            "4/4 - 0s - loss: 3.3028 - accuracy: 0.2050 - val_loss: 3.4487 - val_accuracy: 0.2162 - 54ms/epoch - 14ms/step\n",
            "Epoch 16/200\n",
            "4/4 - 0s - loss: 3.2721 - accuracy: 0.2000 - val_loss: 3.4315 - val_accuracy: 0.2162 - 35ms/epoch - 9ms/step\n",
            "Epoch 17/200\n",
            "4/4 - 0s - loss: 3.2499 - accuracy: 0.2100 - val_loss: 3.4153 - val_accuracy: 0.2703 - 31ms/epoch - 8ms/step\n",
            "Epoch 18/200\n",
            "4/4 - 0s - loss: 3.2224 - accuracy: 0.2350 - val_loss: 3.4068 - val_accuracy: 0.3243 - 31ms/epoch - 8ms/step\n",
            "Epoch 19/200\n",
            "4/4 - 0s - loss: 3.1979 - accuracy: 0.2350 - val_loss: 3.3989 - val_accuracy: 0.3243 - 31ms/epoch - 8ms/step\n",
            "Epoch 20/200\n",
            "4/4 - 0s - loss: 3.1733 - accuracy: 0.2500 - val_loss: 3.3930 - val_accuracy: 0.3243 - 31ms/epoch - 8ms/step\n",
            "Epoch 21/200\n",
            "4/4 - 0s - loss: 3.1467 - accuracy: 0.2600 - val_loss: 3.3861 - val_accuracy: 0.3243 - 50ms/epoch - 13ms/step\n",
            "Epoch 22/200\n",
            "4/4 - 0s - loss: 3.1241 - accuracy: 0.2600 - val_loss: 3.3656 - val_accuracy: 0.3243 - 31ms/epoch - 8ms/step\n",
            "Epoch 23/200\n",
            "4/4 - 0s - loss: 3.0953 - accuracy: 0.2700 - val_loss: 3.3494 - val_accuracy: 0.3243 - 49ms/epoch - 12ms/step\n",
            "Epoch 24/200\n",
            "4/4 - 0s - loss: 3.0678 - accuracy: 0.2550 - val_loss: 3.3297 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "4/4 - 0s - loss: 3.0390 - accuracy: 0.2600 - val_loss: 3.3138 - val_accuracy: 0.2973 - 30ms/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "4/4 - 0s - loss: 3.0126 - accuracy: 0.2800 - val_loss: 3.3010 - val_accuracy: 0.2973 - 30ms/epoch - 8ms/step\n",
            "Epoch 27/200\n",
            "4/4 - 0s - loss: 2.9861 - accuracy: 0.3000 - val_loss: 3.2889 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "4/4 - 0s - loss: 2.9610 - accuracy: 0.3100 - val_loss: 3.2797 - val_accuracy: 0.3243 - 30ms/epoch - 8ms/step\n",
            "Epoch 29/200\n",
            "4/4 - 0s - loss: 2.9368 - accuracy: 0.3100 - val_loss: 3.2678 - val_accuracy: 0.2973 - 32ms/epoch - 8ms/step\n",
            "Epoch 30/200\n",
            "4/4 - 0s - loss: 2.9156 - accuracy: 0.3150 - val_loss: 3.2622 - val_accuracy: 0.2973 - 51ms/epoch - 13ms/step\n",
            "Epoch 31/200\n",
            "4/4 - 0s - loss: 2.8882 - accuracy: 0.3100 - val_loss: 3.2551 - val_accuracy: 0.2973 - 32ms/epoch - 8ms/step\n",
            "Epoch 32/200\n",
            "4/4 - 0s - loss: 2.8677 - accuracy: 0.3150 - val_loss: 3.2474 - val_accuracy: 0.2973 - 36ms/epoch - 9ms/step\n",
            "Epoch 33/200\n",
            "4/4 - 0s - loss: 2.8420 - accuracy: 0.3300 - val_loss: 3.2478 - val_accuracy: 0.2973 - 36ms/epoch - 9ms/step\n",
            "Epoch 34/200\n",
            "4/4 - 0s - loss: 2.8172 - accuracy: 0.3550 - val_loss: 3.2425 - val_accuracy: 0.2973 - 34ms/epoch - 8ms/step\n",
            "Epoch 35/200\n",
            "4/4 - 0s - loss: 2.7906 - accuracy: 0.3500 - val_loss: 3.2379 - val_accuracy: 0.2973 - 33ms/epoch - 8ms/step\n",
            "Epoch 36/200\n",
            "4/4 - 0s - loss: 2.7665 - accuracy: 0.3600 - val_loss: 3.2348 - val_accuracy: 0.2973 - 31ms/epoch - 8ms/step\n",
            "Epoch 37/200\n",
            "4/4 - 0s - loss: 2.7415 - accuracy: 0.3550 - val_loss: 3.2335 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "4/4 - 0s - loss: 2.7205 - accuracy: 0.3550 - val_loss: 3.2346 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "4/4 - 0s - loss: 2.6977 - accuracy: 0.3600 - val_loss: 3.2304 - val_accuracy: 0.2973 - 33ms/epoch - 8ms/step\n",
            "Epoch 40/200\n",
            "4/4 - 0s - loss: 2.6736 - accuracy: 0.3750 - val_loss: 3.2422 - val_accuracy: 0.2703 - 29ms/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "4/4 - 0s - loss: 2.6509 - accuracy: 0.3650 - val_loss: 3.2540 - val_accuracy: 0.2973 - 31ms/epoch - 8ms/step\n",
            "Epoch 42/200\n",
            "4/4 - 0s - loss: 2.6252 - accuracy: 0.3750 - val_loss: 3.2561 - val_accuracy: 0.2703 - 31ms/epoch - 8ms/step\n",
            "Epoch 43/200\n",
            "4/4 - 0s - loss: 2.6058 - accuracy: 0.3700 - val_loss: 3.2612 - val_accuracy: 0.2703 - 29ms/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "4/4 - 0s - loss: 2.5788 - accuracy: 0.3800 - val_loss: 3.2831 - val_accuracy: 0.2703 - 30ms/epoch - 8ms/step\n",
            "Epoch 45/200\n",
            "4/4 - 0s - loss: 2.5567 - accuracy: 0.3800 - val_loss: 3.3007 - val_accuracy: 0.2973 - 36ms/epoch - 9ms/step\n",
            "Epoch 46/200\n",
            "4/4 - 0s - loss: 2.5365 - accuracy: 0.3700 - val_loss: 3.3181 - val_accuracy: 0.2973 - 39ms/epoch - 10ms/step\n",
            "Epoch 47/200\n",
            "4/4 - 0s - loss: 2.5114 - accuracy: 0.3750 - val_loss: 3.3201 - val_accuracy: 0.2973 - 31ms/epoch - 8ms/step\n",
            "Epoch 48/200\n",
            "4/4 - 0s - loss: 2.4938 - accuracy: 0.3650 - val_loss: 3.3338 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "4/4 - 0s - loss: 2.4725 - accuracy: 0.3500 - val_loss: 3.3494 - val_accuracy: 0.2432 - 30ms/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "4/4 - 0s - loss: 2.4493 - accuracy: 0.3400 - val_loss: 3.3715 - val_accuracy: 0.2162 - 31ms/epoch - 8ms/step\n",
            "Epoch 51/200\n",
            "4/4 - 0s - loss: 2.4280 - accuracy: 0.3350 - val_loss: 3.3685 - val_accuracy: 0.2162 - 31ms/epoch - 8ms/step\n",
            "Epoch 52/200\n",
            "4/4 - 0s - loss: 2.4047 - accuracy: 0.3250 - val_loss: 3.3650 - val_accuracy: 0.1892 - 29ms/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "4/4 - 0s - loss: 2.3811 - accuracy: 0.3150 - val_loss: 3.3459 - val_accuracy: 0.1892 - 33ms/epoch - 8ms/step\n",
            "Epoch 54/200\n",
            "4/4 - 0s - loss: 2.3557 - accuracy: 0.3350 - val_loss: 3.3606 - val_accuracy: 0.1892 - 35ms/epoch - 9ms/step\n",
            "Epoch 55/200\n",
            "4/4 - 0s - loss: 2.3325 - accuracy: 0.3300 - val_loss: 3.3837 - val_accuracy: 0.1892 - 34ms/epoch - 9ms/step\n",
            "Epoch 56/200\n",
            "4/4 - 0s - loss: 2.3046 - accuracy: 0.3300 - val_loss: 3.4263 - val_accuracy: 0.1351 - 32ms/epoch - 8ms/step\n",
            "Epoch 57/200\n",
            "4/4 - 0s - loss: 2.2737 - accuracy: 0.3250 - val_loss: 3.4467 - val_accuracy: 0.1081 - 30ms/epoch - 8ms/step\n",
            "Epoch 58/200\n",
            "4/4 - 0s - loss: 2.2451 - accuracy: 0.3250 - val_loss: 3.4731 - val_accuracy: 0.1081 - 31ms/epoch - 8ms/step\n",
            "Epoch 59/200\n",
            "4/4 - 0s - loss: 2.2156 - accuracy: 0.3050 - val_loss: 3.4658 - val_accuracy: 0.1351 - 32ms/epoch - 8ms/step\n",
            "Epoch 60/200\n",
            "4/4 - 0s - loss: 2.1873 - accuracy: 0.3150 - val_loss: 3.4695 - val_accuracy: 0.1351 - 33ms/epoch - 8ms/step\n",
            "Epoch 61/200\n",
            "4/4 - 0s - loss: 2.1599 - accuracy: 0.3100 - val_loss: 3.4631 - val_accuracy: 0.1081 - 48ms/epoch - 12ms/step\n",
            "Epoch 62/200\n",
            "4/4 - 0s - loss: 2.1360 - accuracy: 0.3150 - val_loss: 3.4281 - val_accuracy: 0.1081 - 30ms/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "4/4 - 0s - loss: 2.1051 - accuracy: 0.3100 - val_loss: 3.4328 - val_accuracy: 0.1081 - 33ms/epoch - 8ms/step\n",
            "Epoch 64/200\n",
            "4/4 - 0s - loss: 2.0792 - accuracy: 0.3100 - val_loss: 3.4152 - val_accuracy: 0.1081 - 31ms/epoch - 8ms/step\n",
            "Epoch 65/200\n",
            "4/4 - 0s - loss: 2.0476 - accuracy: 0.3150 - val_loss: 3.4099 - val_accuracy: 0.1081 - 29ms/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "4/4 - 0s - loss: 2.0242 - accuracy: 0.3050 - val_loss: 3.4032 - val_accuracy: 0.1081 - 51ms/epoch - 13ms/step\n",
            "Epoch 67/200\n",
            "4/4 - 0s - loss: 1.9948 - accuracy: 0.3150 - val_loss: 3.4145 - val_accuracy: 0.1081 - 35ms/epoch - 9ms/step\n",
            "Epoch 68/200\n",
            "4/4 - 0s - loss: 1.9667 - accuracy: 0.3250 - val_loss: 3.4231 - val_accuracy: 0.1081 - 30ms/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "4/4 - 0s - loss: 1.9382 - accuracy: 0.3250 - val_loss: 3.4108 - val_accuracy: 0.1081 - 30ms/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "4/4 - 0s - loss: 1.9064 - accuracy: 0.3250 - val_loss: 3.3458 - val_accuracy: 0.0811 - 53ms/epoch - 13ms/step\n",
            "Epoch 71/200\n",
            "4/4 - 0s - loss: 1.8696 - accuracy: 0.3450 - val_loss: 3.3309 - val_accuracy: 0.0811 - 30ms/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "4/4 - 0s - loss: 1.8375 - accuracy: 0.3500 - val_loss: 3.3326 - val_accuracy: 0.0811 - 31ms/epoch - 8ms/step\n",
            "Epoch 73/200\n",
            "4/4 - 0s - loss: 1.8073 - accuracy: 0.3550 - val_loss: 3.3201 - val_accuracy: 0.0811 - 30ms/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "4/4 - 0s - loss: 1.7681 - accuracy: 0.3600 - val_loss: 3.2603 - val_accuracy: 0.0811 - 31ms/epoch - 8ms/step\n",
            "Epoch 75/200\n",
            "4/4 - 0s - loss: 1.7316 - accuracy: 0.3600 - val_loss: 3.1923 - val_accuracy: 0.0811 - 30ms/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "4/4 - 0s - loss: 1.6917 - accuracy: 0.3550 - val_loss: 3.1225 - val_accuracy: 0.1081 - 50ms/epoch - 12ms/step\n",
            "Epoch 77/200\n",
            "4/4 - 0s - loss: 1.6465 - accuracy: 0.3850 - val_loss: 3.0781 - val_accuracy: 0.1622 - 51ms/epoch - 13ms/step\n",
            "Epoch 78/200\n",
            "4/4 - 0s - loss: 1.6039 - accuracy: 0.5150 - val_loss: 3.0404 - val_accuracy: 0.3784 - 34ms/epoch - 8ms/step\n",
            "Epoch 79/200\n",
            "4/4 - 0s - loss: 1.5570 - accuracy: 0.5900 - val_loss: 3.0280 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 80/200\n",
            "4/4 - 0s - loss: 1.5111 - accuracy: 0.6000 - val_loss: 3.0037 - val_accuracy: 0.4324 - 39ms/epoch - 10ms/step\n",
            "Epoch 81/200\n",
            "4/4 - 0s - loss: 1.4560 - accuracy: 0.6000 - val_loss: 2.9737 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 82/200\n",
            "4/4 - 0s - loss: 1.4223 - accuracy: 0.6050 - val_loss: 3.0117 - val_accuracy: 0.4324 - 30ms/epoch - 8ms/step\n",
            "Epoch 83/200\n",
            "4/4 - 0s - loss: 1.3760 - accuracy: 0.6200 - val_loss: 3.0582 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "4/4 - 0s - loss: 1.3490 - accuracy: 0.6300 - val_loss: 3.0868 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "4/4 - 0s - loss: 1.3262 - accuracy: 0.6300 - val_loss: 3.0784 - val_accuracy: 0.4324 - 34ms/epoch - 8ms/step\n",
            "Epoch 86/200\n",
            "4/4 - 0s - loss: 1.3086 - accuracy: 0.6300 - val_loss: 3.0801 - val_accuracy: 0.4054 - 29ms/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "4/4 - 0s - loss: 1.2921 - accuracy: 0.6200 - val_loss: 3.1010 - val_accuracy: 0.4054 - 40ms/epoch - 10ms/step\n",
            "Epoch 88/200\n",
            "4/4 - 0s - loss: 1.2755 - accuracy: 0.6250 - val_loss: 3.1072 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 89/200\n",
            "4/4 - 0s - loss: 1.2628 - accuracy: 0.6250 - val_loss: 3.1135 - val_accuracy: 0.4054 - 30ms/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "4/4 - 0s - loss: 1.2446 - accuracy: 0.6250 - val_loss: 3.1156 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 91/200\n",
            "4/4 - 0s - loss: 1.2367 - accuracy: 0.6300 - val_loss: 3.0920 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 92/200\n",
            "4/4 - 0s - loss: 1.2213 - accuracy: 0.6300 - val_loss: 3.1222 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 93/200\n",
            "4/4 - 0s - loss: 1.2044 - accuracy: 0.6300 - val_loss: 3.1645 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 94/200\n",
            "4/4 - 0s - loss: 1.1941 - accuracy: 0.6300 - val_loss: 3.1838 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 95/200\n",
            "4/4 - 0s - loss: 1.1794 - accuracy: 0.6300 - val_loss: 3.2041 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 96/200\n",
            "4/4 - 0s - loss: 1.1689 - accuracy: 0.6300 - val_loss: 3.1804 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 97/200\n",
            "4/4 - 0s - loss: 1.1598 - accuracy: 0.6350 - val_loss: 3.1894 - val_accuracy: 0.4054 - 30ms/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "4/4 - 0s - loss: 1.1499 - accuracy: 0.6350 - val_loss: 3.1944 - val_accuracy: 0.4054 - 30ms/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "4/4 - 0s - loss: 1.1386 - accuracy: 0.6350 - val_loss: 3.2088 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 100/200\n",
            "4/4 - 0s - loss: 1.1284 - accuracy: 0.6350 - val_loss: 3.2121 - val_accuracy: 0.4054 - 49ms/epoch - 12ms/step\n",
            "Epoch 101/200\n",
            "4/4 - 0s - loss: 1.1207 - accuracy: 0.6400 - val_loss: 3.2375 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 102/200\n",
            "4/4 - 0s - loss: 1.1125 - accuracy: 0.6400 - val_loss: 3.2560 - val_accuracy: 0.4054 - 52ms/epoch - 13ms/step\n",
            "Epoch 103/200\n",
            "4/4 - 0s - loss: 1.1020 - accuracy: 0.6450 - val_loss: 3.2593 - val_accuracy: 0.4054 - 32ms/epoch - 8ms/step\n",
            "Epoch 104/200\n",
            "4/4 - 0s - loss: 1.0924 - accuracy: 0.6450 - val_loss: 3.2403 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 105/200\n",
            "4/4 - 0s - loss: 1.0873 - accuracy: 0.6450 - val_loss: 3.2438 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 106/200\n",
            "4/4 - 0s - loss: 1.0805 - accuracy: 0.6450 - val_loss: 3.2689 - val_accuracy: 0.4054 - 32ms/epoch - 8ms/step\n",
            "Epoch 107/200\n",
            "4/4 - 0s - loss: 1.0806 - accuracy: 0.6500 - val_loss: 3.3564 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 108/200\n",
            "4/4 - 0s - loss: 1.0602 - accuracy: 0.6600 - val_loss: 3.3545 - val_accuracy: 0.4054 - 28ms/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "4/4 - 0s - loss: 1.0530 - accuracy: 0.6600 - val_loss: 3.3135 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 110/200\n",
            "4/4 - 0s - loss: 1.0374 - accuracy: 0.6550 - val_loss: 3.3717 - val_accuracy: 0.4054 - 34ms/epoch - 9ms/step\n",
            "Epoch 111/200\n",
            "4/4 - 0s - loss: 1.0316 - accuracy: 0.6550 - val_loss: 3.3910 - val_accuracy: 0.4054 - 52ms/epoch - 13ms/step\n",
            "Epoch 112/200\n",
            "4/4 - 0s - loss: 1.0213 - accuracy: 0.6550 - val_loss: 3.3841 - val_accuracy: 0.4054 - 29ms/epoch - 7ms/step\n",
            "Epoch 113/200\n",
            "4/4 - 0s - loss: 1.0072 - accuracy: 0.6600 - val_loss: 3.4441 - val_accuracy: 0.4054 - 38ms/epoch - 9ms/step\n",
            "Epoch 114/200\n",
            "4/4 - 0s - loss: 0.9980 - accuracy: 0.6650 - val_loss: 3.4753 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 115/200\n",
            "4/4 - 0s - loss: 0.9861 - accuracy: 0.6700 - val_loss: 3.4679 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 116/200\n",
            "4/4 - 0s - loss: 0.9757 - accuracy: 0.6700 - val_loss: 3.5206 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 117/200\n",
            "4/4 - 0s - loss: 0.9677 - accuracy: 0.6750 - val_loss: 3.5544 - val_accuracy: 0.4054 - 50ms/epoch - 13ms/step\n",
            "Epoch 118/200\n",
            "4/4 - 0s - loss: 0.9620 - accuracy: 0.6750 - val_loss: 3.6003 - val_accuracy: 0.4054 - 30ms/epoch - 7ms/step\n",
            "Epoch 119/200\n",
            "4/4 - 0s - loss: 0.9514 - accuracy: 0.6700 - val_loss: 3.5627 - val_accuracy: 0.4054 - 52ms/epoch - 13ms/step\n",
            "Epoch 120/200\n",
            "4/4 - 0s - loss: 0.9459 - accuracy: 0.6750 - val_loss: 3.5828 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 121/200\n",
            "4/4 - 0s - loss: 0.9407 - accuracy: 0.6700 - val_loss: 3.6232 - val_accuracy: 0.4054 - 35ms/epoch - 9ms/step\n",
            "Epoch 122/200\n",
            "4/4 - 0s - loss: 0.9354 - accuracy: 0.6700 - val_loss: 3.6109 - val_accuracy: 0.4054 - 34ms/epoch - 8ms/step\n",
            "Epoch 123/200\n",
            "4/4 - 0s - loss: 0.9306 - accuracy: 0.6800 - val_loss: 3.6139 - val_accuracy: 0.4054 - 32ms/epoch - 8ms/step\n",
            "Epoch 124/200\n",
            "4/4 - 0s - loss: 0.9228 - accuracy: 0.6800 - val_loss: 3.6413 - val_accuracy: 0.4054 - 54ms/epoch - 14ms/step\n",
            "Epoch 125/200\n",
            "4/4 - 0s - loss: 0.9214 - accuracy: 0.6800 - val_loss: 3.6259 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 126/200\n",
            "4/4 - 0s - loss: 0.9170 - accuracy: 0.6800 - val_loss: 3.7024 - val_accuracy: 0.4054 - 38ms/epoch - 9ms/step\n",
            "Epoch 127/200\n",
            "4/4 - 0s - loss: 0.9145 - accuracy: 0.6800 - val_loss: 3.6681 - val_accuracy: 0.4054 - 38ms/epoch - 10ms/step\n",
            "Epoch 128/200\n",
            "4/4 - 0s - loss: 0.9078 - accuracy: 0.6800 - val_loss: 3.6855 - val_accuracy: 0.4054 - 35ms/epoch - 9ms/step\n",
            "Epoch 129/200\n",
            "4/4 - 0s - loss: 0.8988 - accuracy: 0.6800 - val_loss: 3.7041 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 130/200\n",
            "4/4 - 0s - loss: 0.8929 - accuracy: 0.6850 - val_loss: 3.7528 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 131/200\n",
            "4/4 - 0s - loss: 0.8870 - accuracy: 0.6850 - val_loss: 3.7385 - val_accuracy: 0.4324 - 34ms/epoch - 8ms/step\n",
            "Epoch 132/200\n",
            "4/4 - 0s - loss: 0.8824 - accuracy: 0.6850 - val_loss: 3.7534 - val_accuracy: 0.4324 - 49ms/epoch - 12ms/step\n",
            "Epoch 133/200\n",
            "4/4 - 0s - loss: 0.8759 - accuracy: 0.6850 - val_loss: 3.8107 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 134/200\n",
            "4/4 - 0s - loss: 0.8662 - accuracy: 0.6850 - val_loss: 3.8424 - val_accuracy: 0.4324 - 32ms/epoch - 8ms/step\n",
            "Epoch 135/200\n",
            "4/4 - 0s - loss: 0.8566 - accuracy: 0.6900 - val_loss: 3.8372 - val_accuracy: 0.4324 - 35ms/epoch - 9ms/step\n",
            "Epoch 136/200\n",
            "4/4 - 0s - loss: 0.8506 - accuracy: 0.6900 - val_loss: 3.8578 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 137/200\n",
            "4/4 - 0s - loss: 0.8469 - accuracy: 0.6900 - val_loss: 3.8371 - val_accuracy: 0.4324 - 32ms/epoch - 8ms/step\n",
            "Epoch 138/200\n",
            "4/4 - 0s - loss: 0.8476 - accuracy: 0.6900 - val_loss: 3.9399 - val_accuracy: 0.4324 - 30ms/epoch - 8ms/step\n",
            "Epoch 139/200\n",
            "4/4 - 0s - loss: 0.8397 - accuracy: 0.6950 - val_loss: 3.8896 - val_accuracy: 0.4324 - 40ms/epoch - 10ms/step\n",
            "Epoch 140/200\n",
            "4/4 - 0s - loss: 0.8353 - accuracy: 0.6950 - val_loss: 4.0482 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 141/200\n",
            "4/4 - 0s - loss: 0.8378 - accuracy: 0.7050 - val_loss: 4.0206 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 142/200\n",
            "4/4 - 0s - loss: 0.8179 - accuracy: 0.6950 - val_loss: 3.9666 - val_accuracy: 0.4324 - 30ms/epoch - 8ms/step\n",
            "Epoch 143/200\n",
            "4/4 - 0s - loss: 0.8124 - accuracy: 0.7050 - val_loss: 4.0368 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 144/200\n",
            "4/4 - 0s - loss: 0.8056 - accuracy: 0.7250 - val_loss: 4.0428 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 145/200\n",
            "4/4 - 0s - loss: 0.7976 - accuracy: 0.7400 - val_loss: 4.0915 - val_accuracy: 0.4324 - 36ms/epoch - 9ms/step\n",
            "Epoch 146/200\n",
            "4/4 - 0s - loss: 0.7918 - accuracy: 0.7400 - val_loss: 4.1254 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 147/200\n",
            "4/4 - 0s - loss: 0.7871 - accuracy: 0.7400 - val_loss: 4.1913 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 148/200\n",
            "4/4 - 0s - loss: 0.7792 - accuracy: 0.7400 - val_loss: 4.2158 - val_accuracy: 0.4595 - 31ms/epoch - 8ms/step\n",
            "Epoch 149/200\n",
            "4/4 - 0s - loss: 0.7749 - accuracy: 0.7500 - val_loss: 4.2227 - val_accuracy: 0.4595 - 33ms/epoch - 8ms/step\n",
            "Epoch 150/200\n",
            "4/4 - 0s - loss: 0.7696 - accuracy: 0.7500 - val_loss: 4.2720 - val_accuracy: 0.4595 - 36ms/epoch - 9ms/step\n",
            "Epoch 151/200\n",
            "4/4 - 0s - loss: 0.7646 - accuracy: 0.7500 - val_loss: 4.2501 - val_accuracy: 0.4595 - 30ms/epoch - 8ms/step\n",
            "Epoch 152/200\n",
            "4/4 - 0s - loss: 0.7614 - accuracy: 0.7500 - val_loss: 4.2852 - val_accuracy: 0.4595 - 33ms/epoch - 8ms/step\n",
            "Epoch 153/200\n",
            "4/4 - 0s - loss: 0.7581 - accuracy: 0.7550 - val_loss: 4.3489 - val_accuracy: 0.4595 - 31ms/epoch - 8ms/step\n",
            "Epoch 154/200\n",
            "4/4 - 0s - loss: 0.7520 - accuracy: 0.7550 - val_loss: 4.3340 - val_accuracy: 0.4595 - 32ms/epoch - 8ms/step\n",
            "Epoch 155/200\n",
            "4/4 - 0s - loss: 0.7470 - accuracy: 0.7700 - val_loss: 4.3459 - val_accuracy: 0.4595 - 37ms/epoch - 9ms/step\n",
            "Epoch 156/200\n",
            "4/4 - 0s - loss: 0.7420 - accuracy: 0.7650 - val_loss: 4.3851 - val_accuracy: 0.4595 - 30ms/epoch - 7ms/step\n",
            "Epoch 157/200\n",
            "4/4 - 0s - loss: 0.7395 - accuracy: 0.7650 - val_loss: 4.3946 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 158/200\n",
            "4/4 - 0s - loss: 0.7350 - accuracy: 0.7650 - val_loss: 4.4355 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 159/200\n",
            "4/4 - 0s - loss: 0.7285 - accuracy: 0.7700 - val_loss: 4.4781 - val_accuracy: 0.4595 - 29ms/epoch - 7ms/step\n",
            "Epoch 160/200\n",
            "4/4 - 0s - loss: 0.7251 - accuracy: 0.7650 - val_loss: 4.4693 - val_accuracy: 0.4595 - 34ms/epoch - 8ms/step\n",
            "Epoch 161/200\n",
            "4/4 - 0s - loss: 0.7168 - accuracy: 0.7700 - val_loss: 4.4883 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 162/200\n",
            "4/4 - 0s - loss: 0.7122 - accuracy: 0.7750 - val_loss: 4.5612 - val_accuracy: 0.4595 - 32ms/epoch - 8ms/step\n",
            "Epoch 163/200\n",
            "4/4 - 0s - loss: 0.7064 - accuracy: 0.7750 - val_loss: 4.5629 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 164/200\n",
            "4/4 - 0s - loss: 0.7016 - accuracy: 0.7700 - val_loss: 4.6008 - val_accuracy: 0.4324 - 34ms/epoch - 8ms/step\n",
            "Epoch 165/200\n",
            "4/4 - 0s - loss: 0.6975 - accuracy: 0.7700 - val_loss: 4.5803 - val_accuracy: 0.4324 - 37ms/epoch - 9ms/step\n",
            "Epoch 166/200\n",
            "4/4 - 0s - loss: 0.6940 - accuracy: 0.7700 - val_loss: 4.5932 - val_accuracy: 0.4324 - 35ms/epoch - 9ms/step\n",
            "Epoch 167/200\n",
            "4/4 - 0s - loss: 0.6887 - accuracy: 0.7750 - val_loss: 4.6614 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 168/200\n",
            "4/4 - 0s - loss: 0.6875 - accuracy: 0.7650 - val_loss: 4.6683 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 169/200\n",
            "4/4 - 0s - loss: 0.6830 - accuracy: 0.7800 - val_loss: 4.6536 - val_accuracy: 0.4324 - 35ms/epoch - 9ms/step\n",
            "Epoch 170/200\n",
            "4/4 - 0s - loss: 0.6772 - accuracy: 0.7850 - val_loss: 4.6915 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 171/200\n",
            "4/4 - 0s - loss: 0.6715 - accuracy: 0.7850 - val_loss: 4.6998 - val_accuracy: 0.4324 - 34ms/epoch - 9ms/step\n",
            "Epoch 172/200\n",
            "4/4 - 0s - loss: 0.6641 - accuracy: 0.7850 - val_loss: 4.7301 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 173/200\n",
            "4/4 - 0s - loss: 0.6582 - accuracy: 0.7950 - val_loss: 4.7660 - val_accuracy: 0.4324 - 35ms/epoch - 9ms/step\n",
            "Epoch 174/200\n",
            "4/4 - 0s - loss: 0.6543 - accuracy: 0.8000 - val_loss: 4.8123 - val_accuracy: 0.4595 - 32ms/epoch - 8ms/step\n",
            "Epoch 175/200\n",
            "4/4 - 0s - loss: 0.6485 - accuracy: 0.8000 - val_loss: 4.8346 - val_accuracy: 0.4595 - 28ms/epoch - 7ms/step\n",
            "Epoch 176/200\n",
            "4/4 - 0s - loss: 0.6423 - accuracy: 0.8000 - val_loss: 4.9152 - val_accuracy: 0.4324 - 36ms/epoch - 9ms/step\n",
            "Epoch 177/200\n",
            "4/4 - 0s - loss: 0.6375 - accuracy: 0.8050 - val_loss: 4.9034 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 178/200\n",
            "4/4 - 0s - loss: 0.6320 - accuracy: 0.8000 - val_loss: 4.8864 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 179/200\n",
            "4/4 - 0s - loss: 0.6304 - accuracy: 0.8100 - val_loss: 4.9372 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 180/200\n",
            "4/4 - 0s - loss: 0.6253 - accuracy: 0.8000 - val_loss: 4.9664 - val_accuracy: 0.4324 - 38ms/epoch - 9ms/step\n",
            "Epoch 181/200\n",
            "4/4 - 0s - loss: 0.6229 - accuracy: 0.8050 - val_loss: 4.9734 - val_accuracy: 0.4054 - 34ms/epoch - 8ms/step\n",
            "Epoch 182/200\n",
            "4/4 - 0s - loss: 0.6175 - accuracy: 0.8050 - val_loss: 5.0064 - val_accuracy: 0.4054 - 35ms/epoch - 9ms/step\n",
            "Epoch 183/200\n",
            "4/4 - 0s - loss: 0.6141 - accuracy: 0.8150 - val_loss: 4.9811 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 184/200\n",
            "4/4 - 0s - loss: 0.6107 - accuracy: 0.8050 - val_loss: 5.0561 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 185/200\n",
            "4/4 - 0s - loss: 0.6087 - accuracy: 0.8100 - val_loss: 5.0340 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 186/200\n",
            "4/4 - 0s - loss: 0.6043 - accuracy: 0.8100 - val_loss: 5.0590 - val_accuracy: 0.4324 - 42ms/epoch - 10ms/step\n",
            "Epoch 187/200\n",
            "4/4 - 0s - loss: 0.6016 - accuracy: 0.8150 - val_loss: 5.1389 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 188/200\n",
            "4/4 - 0s - loss: 0.5984 - accuracy: 0.8050 - val_loss: 5.1434 - val_accuracy: 0.4324 - 49ms/epoch - 12ms/step\n",
            "Epoch 189/200\n",
            "4/4 - 0s - loss: 0.5955 - accuracy: 0.8100 - val_loss: 5.1216 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 190/200\n",
            "4/4 - 0s - loss: 0.5935 - accuracy: 0.8000 - val_loss: 5.1814 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 191/200\n",
            "4/4 - 0s - loss: 0.5899 - accuracy: 0.8050 - val_loss: 5.1869 - val_accuracy: 0.4054 - 28ms/epoch - 7ms/step\n",
            "Epoch 192/200\n",
            "4/4 - 0s - loss: 0.5869 - accuracy: 0.8150 - val_loss: 5.2024 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 193/200\n",
            "4/4 - 0s - loss: 0.5841 - accuracy: 0.8100 - val_loss: 5.2228 - val_accuracy: 0.4324 - 28ms/epoch - 7ms/step\n",
            "Epoch 194/200\n",
            "4/4 - 0s - loss: 0.5828 - accuracy: 0.8100 - val_loss: 5.2386 - val_accuracy: 0.4324 - 44ms/epoch - 11ms/step\n",
            "Epoch 195/200\n",
            "4/4 - 0s - loss: 0.5836 - accuracy: 0.8150 - val_loss: 5.2861 - val_accuracy: 0.4324 - 32ms/epoch - 8ms/step\n",
            "Epoch 196/200\n",
            "4/4 - 0s - loss: 0.5742 - accuracy: 0.8050 - val_loss: 5.2691 - val_accuracy: 0.4324 - 36ms/epoch - 9ms/step\n",
            "Epoch 197/200\n",
            "4/4 - 0s - loss: 0.5688 - accuracy: 0.8150 - val_loss: 5.2846 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 198/200\n",
            "4/4 - 0s - loss: 0.5669 - accuracy: 0.8200 - val_loss: 5.2860 - val_accuracy: 0.4324 - 47ms/epoch - 12ms/step\n",
            "Epoch 199/200\n",
            "4/4 - 0s - loss: 0.5631 - accuracy: 0.8200 - val_loss: 5.3274 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 200/200\n",
            "4/4 - 0s - loss: 0.5618 - accuracy: 0.8150 - val_loss: 5.3562 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "seconds= 11.093770503997803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('primer_intento.h5')"
      ],
      "metadata": {
        "id": "qNN7Vb00PLUL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "test_predicted_labels = model.predict(X_total[200:])\n",
        "test_true_labels      = np.argmax(Y_total[200:],axis=1)\n",
        "test_predicted_labels = np.argmax(test_predicted_labels,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iek95NWhuTME",
        "outputId": "bcddac6e-1558-4f0d-bbb2-5bec7053e52c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Podríamos implementar metricas, accuracy, recall, F1, AUC, etc."
      ],
      "metadata": {
        "id": "9O-LcdNwz8Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segundo intento. Leave One Out Cross Validation Method."
      ],
      "metadata": {
        "id": "rYu2VOad4e2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sean $X_1,X_2,\\ldots, X_n$ las observaciones. \n",
        "Para cada $i\\in\\{1,2,\\ldots,n\\}$ se define una red $RN(i)$, que es entrenada con los datos \n",
        "$$X_{train}^{(i)}=\\{X\\}_{i=1}^n - \\{X_i\\}$$\n",
        "$$X_{val}^{(i)}=\\{X_i\\}$$\n",
        "\n",
        "\n",
        "Sea $Y_{pred}^{(i)}=RN(i)(X_i)$ la predicción del dato de entrenamiento.\n",
        "\n",
        "Para cada $i$, se obtiene un error $\\epsilon_i\\in\\{0,1\\}$.\n",
        "\n",
        "Definimos una precisión global como \n",
        "$$\\frac{1}{n}\\sum_{i=1}^n \\epsilon_i$$"
      ],
      "metadata": {
        "id": "pRGzMDUp4mj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "df = pd.read_csv(\"Dataset_w_tags.csv\")\n",
        "df.head()\n",
        "y_tags=df['Tag']\n",
        "df_X=df.drop(columns=['Tag','Dominant_taxa_ID/ID_Environmental'])\n",
        "_,idx_Total = np.unique(y_tags,return_inverse=True)\n",
        "#from sklearn.utils import shuffle\n",
        "#df = shuffle(df)###El ajuste depende de este shuffle"
      ],
      "metadata": {
        "id": "PN3ik5Bk7dZB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(idx_Total,bins=37)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "XXtvMrTAmaFy",
        "outputId": "8d1cbb04-8059-40e2-e79c-a22911a5b643"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 1.,  3.,  4.,  3., 11., 16.,  1.,  3.,  1.,  1., 60.,  2.,  7.,\n",
              "        16.,  4.,  2.,  2.,  9.,  1.,  6., 24.,  2.,  4.,  1.,  3.,  1.,\n",
              "         2.,  5.,  3.,  2.,  2.,  1., 22.,  3.,  1.,  1.,  7.]),\n",
              " array([ 0.        ,  0.97297297,  1.94594595,  2.91891892,  3.89189189,\n",
              "         4.86486486,  5.83783784,  6.81081081,  7.78378378,  8.75675676,\n",
              "         9.72972973, 10.7027027 , 11.67567568, 12.64864865, 13.62162162,\n",
              "        14.59459459, 15.56756757, 16.54054054, 17.51351351, 18.48648649,\n",
              "        19.45945946, 20.43243243, 21.40540541, 22.37837838, 23.35135135,\n",
              "        24.32432432, 25.2972973 , 26.27027027, 27.24324324, 28.21621622,\n",
              "        29.18918919, 30.16216216, 31.13513514, 32.10810811, 33.08108108,\n",
              "        34.05405405, 35.02702703, 36.        ]),\n",
              " <a list of 37 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que en esta base con pocas muestras, hay clases con un único representante, por lo que no tiene sentido dejarlo fuera pues disminuiría el número de clases y por lo tanto una correcta clasificación tiene inmediatamente probabilidad cero."
      ],
      "metadata": {
        "id": "Rziaivnh0KR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como solución improvisada, haremos réplica (¿cuántas veces?) de muestras para aquellas clases con muy pocas (¿cuántas son muy pocas?), para incrementar la representatividad. \n",
        "\n",
        "Esto es equivalente a agregarle pesos de clasificación a estas clases, y un caso extremo sería homogeneizar los números de observaciones por clase de manera que una nueva muestra tenga probabilidad uniforme de provenir de una de las clases. (cita_pendiente)"
      ],
      "metadata": {
        "id": "-9P_FPBW1CTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uniques,ocurr=np.unique(idx_Total,return_counts=True)\n",
        "indices_w_varios=[]\n",
        "for k in range(len(ocurr)):\n",
        "    if ocurr[k]<=2:#Indices de la base donde hay pocos \n",
        "        indices=np.where(idx_Total==k)[0]\n",
        "        df=df.append(df.loc[indices],ignore_index=True)\n",
        "        print(indices)\n",
        "df2=pd.DataFrame(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PXctZD4nb_-",
        "outputId": "e0ac4849-5454-45af-d4d9-5003e5a203c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[148]\n",
            "[31]\n",
            "[16]\n",
            "[66]\n",
            "[142 143]\n",
            "[155 157]\n",
            "[152 153]\n",
            "[25]\n",
            "[133 134]\n",
            "[17]\n",
            "[5]\n",
            "[158 161]\n",
            "[154 156]\n",
            "[200 204]\n",
            "[210]\n",
            "[0]\n",
            "[8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_tags_2=df2['Tag']\n",
        "df2_X=df2.drop(columns=['Tag','Dominant_taxa_ID/ID_Environmental'])\n",
        "a_a,idx2_Total = np.unique(y_tags_2,return_inverse=True)"
      ],
      "metadata": {
        "id": "mHulWL34832f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniques2,ocurr2=np.unique(idx2_Total,return_counts=True)\n",
        "print(ocurr2)"
      ],
      "metadata": {
        "id": "DrhtrFIu9LOK",
        "outputId": "08747bf1-5f29-4381-a9ae-a14e031f506e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2  3  4  3 11 16  2  3  2  2 60  4  7 16  4  4  4  9  2  6 24  4  4  2\n",
            "  3  2  4  5  3  4  4  2 22  3  2  2  7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya no hay clases con únicos elementos ni con solo 2."
      ],
      "metadata": {
        "id": "9nJuwlwb1BnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "batch_size_fijo=10\n",
        "epochs_fijas=10\n",
        "def RN(i):#Recibe $i\\in\\{0,\\ldots,n\\}$\n",
        "    X_total=df2_X\n",
        "    Y_total=idx2_Total\n",
        "    X_train_i=X_total.drop(index=i)\n",
        "    Y_train_i=to_categorical(np.delete(Y_total,i))\n",
        "    X_val=X_total.loc[i]\n",
        "    Y_val=idx2_Total[i]###Que sea de tipo categorical_keras\n",
        "    Y_val_cat=np.zeros(len(uniques))\n",
        "    Y_val_cat[Y_val]=1\n",
        "    \n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(511,), name='Input_Layer'))#Obligatoria\n",
        "    model.add(layers.Dense(512, activation='relu'))# Numero de capas ocultas: Opcional\n",
        "    model.add(layers.Dense(64, activation='relu'))# Numero de neuronas en cada capa: Opcional\n",
        "    model.add(layers.Dense(37, activation='Softmax', name='Output_Layer'))#Obligatoria\n",
        "    #model.summary()\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "# This callback will stop the training when there is no improvement in\n",
        "# the loss for three consecutive epochs.\n",
        "    if(i==0):  \n",
        "        model.fit(x = X_train_i, \n",
        "            y = Y_train_i,\n",
        "            batch_size=batch_size_fijo,\n",
        "            epochs=epochs_fijas,\n",
        "            verbose=2,shuffle=True,callbacks=[callback])\n",
        "    else: \n",
        "        model.fit(x = X_train_i, \n",
        "        y = Y_train_i,\n",
        "        batch_size=batch_size_fijo,\n",
        "        epochs=epochs_fijas,\n",
        "        verbose=0,shuffle=True,callbacks=[callback])\n",
        "    #Asumimos que se terminó de entrenar\n",
        "    return model"
      ],
      "metadata": {
        "id": "9ZVOA4Cs5-Sk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error encontrado: Cuando consideramos suficientes neuronas, podemos conseguir un error de clasificación de los datos de entrenamiento muy cerca del 100%. Esto último se puede identificar como una memorización de estos datos, por lo que la clasificación de nuevos climas sólo tiene sentido para los datos con más de 2 elementos.\n",
        "\n",
        "Se puede considerar una red más sencilla, con menos neuronas de manera que no se aprenda los datos de entrenamiento, sacrificando precisión pero buscando generalidad."
      ],
      "metadata": {
        "id": "-F45NpTELDEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices_prueba"
      ],
      "metadata": {
        "id": "-OH2r0zHRzCK",
        "outputId": "ecc29f4a-5143-44d0-b9bb-6fcca10d0a09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,  57, 201, 160, 111, 200,  94,  36, 116,  28,   6, 245, 240,\n",
              "       114,  56,  54,   1, 225, 243, 125,  33, 136, 187, 236,  14, 167,\n",
              "       117,  31, 190, 139, 108, 134,  98,  35, 166, 208, 156, 169,  64,\n",
              "       180,  37,  50,  46, 109, 242,  92, 229,  82, 209, 126])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_total=df2_X\n",
        "Y_total=idx2_Total\n",
        "pred_trues=[]\n",
        "test_true_labels = np.argmax(to_categorical(Y_total),axis=1)\n",
        "indices_prueba=np.random.choice(range(0,len(X_total)),size=200,replace=False)\n",
        "test_pred_glob=[]\n",
        "if(0 not in indices_prueba):\n",
        "    indices_prueba[0]=0\n",
        "for i in indices_prueba:\n",
        "    test_predicted_labels = RN(i).predict(X_total)\n",
        "    test_predicted_labels = np.argmax(test_predicted_labels,axis=1)\n",
        "    test_pred_glob.append(test_predicted_labels[i])\n"
      ],
      "metadata": {
        "id": "egnpwZS8DtDi",
        "outputId": "efa916cf-0a1e-46f0-c27e-3a614e3b4250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "Epoch 1/10\n",
            "26/26 - 0s - loss: 7.8510 - accuracy: 0.3077 - 390ms/epoch - 15ms/step\n",
            "Epoch 2/10\n",
            "26/26 - 0s - loss: 2.2488 - accuracy: 0.4231 - 54ms/epoch - 2ms/step\n",
            "Epoch 3/10\n",
            "26/26 - 0s - loss: 1.6937 - accuracy: 0.5308 - 63ms/epoch - 2ms/step\n",
            "Epoch 4/10\n",
            "26/26 - 0s - loss: 1.2945 - accuracy: 0.6346 - 63ms/epoch - 2ms/step\n",
            "Epoch 5/10\n",
            "26/26 - 0s - loss: 0.9799 - accuracy: 0.7038 - 55ms/epoch - 2ms/step\n",
            "Epoch 6/10\n",
            "26/26 - 0s - loss: 0.8311 - accuracy: 0.7423 - 56ms/epoch - 2ms/step\n",
            "Epoch 7/10\n",
            "26/26 - 0s - loss: 0.5924 - accuracy: 0.8154 - 54ms/epoch - 2ms/step\n",
            "Epoch 8/10\n",
            "26/26 - 0s - loss: 0.5233 - accuracy: 0.8346 - 55ms/epoch - 2ms/step\n",
            "Epoch 9/10\n",
            "26/26 - 0s - loss: 0.5426 - accuracy: 0.8462 - 54ms/epoch - 2ms/step\n",
            "Epoch 10/10\n",
            "26/26 - 0s - loss: 0.4434 - accuracy: 0.8731 - 54ms/epoch - 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "9/9 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_true_global=test_true_labels[indices_prueba]\n",
        "np.sum(test_pred_glob==test_true_global)/200"
      ],
      "metadata": {
        "id": "bb3S3Pu5b3yZ",
        "outputId": "217de9dd-d57e-4be5-a423-0678a1694d37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtuvimos una precisión de aproximadamente 60% para datos de validación (global).\n"
      ],
      "metadata": {
        "id": "dXG4dmMdTEos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix, precision_score, recall_score,roc_auc_score\n",
        "\n",
        "from sklearn.metrics import f1_score, cohen_kappa_score\n",
        "import seaborn as sns \n",
        "\n",
        "accuracy = accuracy_score(test_true_global, test_pred_glob)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(test_true_global, test_pred_glob,average='weighted',zero_division=1)\n",
        "print('Precision: %f',precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(test_true_global, test_pred_glob,average='weighted',zero_division=1)\n",
        "print('Recall: %f' , recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(test_true_global, test_pred_glob,average='weighted')\n",
        "print('F1 score: %f' % f1)\n"
      ],
      "metadata": {
        "id": "tVPaUGXJYEjo",
        "outputId": "67d135e9-a366-4972-ef45-11ca45c58c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.625000\n",
            "Precision: %f 0.6526153846153846\n",
            "Recall: %f 0.625\n",
            "F1 score: 0.616362\n"
          ]
        }
      ]
    }
  ]
}