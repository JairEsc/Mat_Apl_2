{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzo6J0UbejYg/lPmorVAq0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JairEsc/Mat_Apl_2/blob/main/Biomate_NN_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IklufuqUwcpX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estructura de los datos."
      ],
      "metadata": {
        "id": "MpFOG--QxVDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consideramos un caso general, una base con datos de frecuencias de especies, cada observación de dimensión $k$, y supongamos que tenemos $n$ observaciones.\n",
        "\n",
        "El output busca ser la clasificación en una de $d$ categorías, definidas ya sea por ciudad o localización-clima (pero de un sólo tipo).\n"
      ],
      "metadata": {
        "id": "GznOeGsWxYfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos de ejemplo"
      ],
      "metadata": {
        "id": "NrrajEuRytBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"Dataset_w_tags.csv\")\n",
        "df.head()\n",
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)"
      ],
      "metadata": {
        "id": "30vL3CcXxUUE"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zSWbW5vz3PI",
        "outputId": "90185641-f288-42d1-a086-dc66625c02ee"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 513)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se tienen 237 observaciones, cada una es una muestra en una \"localización\".\n",
        "Por renglón, se tienen frecuencias de \"bichos\" de 510 \"dominant taxa\".\n",
        "\n",
        "En este caso, $k=510$, $n=237$."
      ],
      "metadata": {
        "id": "20gcA30JzhrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytags=df['Tag']\n",
        "print(ytags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I84se6Sw-Mdt",
        "outputId": "2f710bcc-1b64-4dc8-e468-1dcd7b8b73d1"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "234         Cold forests_3\n",
            "230    Temperate forests_0\n",
            "21                Boreal_9\n",
            "228          Dry forests_0\n",
            "137          Dry forests_0\n",
            "              ...         \n",
            "218    Temperate forests_0\n",
            "46       Cold grasslands_1\n",
            "131           Grasslands_2\n",
            "151      Cold grasslands_5\n",
            "41       Cold grasslands_1\n",
            "Name: Tag, Length: 237, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "_,idx = np.unique(ytags,return_inverse=True)"
      ],
      "metadata": {
        "id": "E6fYhQo7BNGu"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados los datos con su respectiva clasificación. (En el ejemplo $d=12$)"
      ],
      "metadata": {
        "id": "6mk01dMO3f12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición del modelo."
      ],
      "metadata": {
        "id": "fOP0O0MV3pmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partición de datos"
      ],
      "metadata": {
        "id": "JydTuMKmF2t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "X_total=df.drop(columns=['Tag','Dominant_taxa_ID/ID_Environmental'])\n",
        "Y_total=to_categorical(idx)"
      ],
      "metadata": {
        "id": "rrhUqdDM4cVL"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_total[0:200]\n",
        "Y_train=Y_total[0:200]"
      ],
      "metadata": {
        "id": "O2iYyd0mGEIW"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "k,n=X_train.shape\n",
        "n=n#-indice, -tag\n",
        "print(k,n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueLx_pz_GAe4",
        "outputId": "72e5b2fd-8a97-4edc-e2fb-864aa8ca0892"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (n,)#=n\n",
        "output_shape=len(np.unique(ytags))"
      ],
      "metadata": {
        "id": "RrB-qCBDB1LX"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "from keras import models\n"
      ],
      "metadata": {
        "id": "XVlSzWd23fCO"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(input_shape=(n,), name='Input_Layer'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(37, activation='Softmax', name='Output_Layer'))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "import time\n",
        "tic = time.time()\n",
        "\n",
        "model.fit(x = X_train, \n",
        "           y = Y_train, \n",
        "          validation_data=[X_total[200:], Y_total[200:]],\n",
        "          batch_size=50,\n",
        "           epochs=20,\n",
        "           verbose=2,shuffle=True)\n",
        "\n",
        "print('seconds=', time.time()-tic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ntg-BtqwqpQ",
        "outputId": "be62f937-1be1-47ba-f9a9-002f08dbb33c"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_46 (Dense)            (None, 64)                32768     \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 37)                1221      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,069\n",
            "Trainable params: 36,069\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "4/4 - 0s - loss: 21.5206 - accuracy: 0.0400 - val_loss: 14.0334 - val_accuracy: 0.1351 - 403ms/epoch - 101ms/step\n",
            "Epoch 2/20\n",
            "4/4 - 0s - loss: 10.2344 - accuracy: 0.1800 - val_loss: 10.6137 - val_accuracy: 0.2162 - 23ms/epoch - 6ms/step\n",
            "Epoch 3/20\n",
            "4/4 - 0s - loss: 6.8388 - accuracy: 0.2800 - val_loss: 8.5256 - val_accuracy: 0.2432 - 23ms/epoch - 6ms/step\n",
            "Epoch 4/20\n",
            "4/4 - 0s - loss: 4.7567 - accuracy: 0.3650 - val_loss: 6.6320 - val_accuracy: 0.2432 - 24ms/epoch - 6ms/step\n",
            "Epoch 5/20\n",
            "4/4 - 0s - loss: 3.5161 - accuracy: 0.4250 - val_loss: 5.6598 - val_accuracy: 0.2973 - 25ms/epoch - 6ms/step\n",
            "Epoch 6/20\n",
            "4/4 - 0s - loss: 2.7022 - accuracy: 0.5000 - val_loss: 5.2078 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 7/20\n",
            "4/4 - 0s - loss: 2.2426 - accuracy: 0.5650 - val_loss: 5.0993 - val_accuracy: 0.3243 - 25ms/epoch - 6ms/step\n",
            "Epoch 8/20\n",
            "4/4 - 0s - loss: 1.9358 - accuracy: 0.5850 - val_loss: 4.9544 - val_accuracy: 0.2973 - 23ms/epoch - 6ms/step\n",
            "Epoch 9/20\n",
            "4/4 - 0s - loss: 1.6488 - accuracy: 0.6200 - val_loss: 4.7895 - val_accuracy: 0.2703 - 25ms/epoch - 6ms/step\n",
            "Epoch 10/20\n",
            "4/4 - 0s - loss: 1.4249 - accuracy: 0.6700 - val_loss: 4.7693 - val_accuracy: 0.2703 - 27ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "4/4 - 0s - loss: 1.2488 - accuracy: 0.6950 - val_loss: 4.7411 - val_accuracy: 0.2703 - 23ms/epoch - 6ms/step\n",
            "Epoch 12/20\n",
            "4/4 - 0s - loss: 1.0748 - accuracy: 0.7300 - val_loss: 4.7302 - val_accuracy: 0.2973 - 26ms/epoch - 7ms/step\n",
            "Epoch 13/20\n",
            "4/4 - 0s - loss: 0.9528 - accuracy: 0.7300 - val_loss: 4.7705 - val_accuracy: 0.2432 - 27ms/epoch - 7ms/step\n",
            "Epoch 14/20\n",
            "4/4 - 0s - loss: 0.8452 - accuracy: 0.7800 - val_loss: 4.8173 - val_accuracy: 0.2432 - 23ms/epoch - 6ms/step\n",
            "Epoch 15/20\n",
            "4/4 - 0s - loss: 0.7506 - accuracy: 0.8100 - val_loss: 4.8281 - val_accuracy: 0.2703 - 23ms/epoch - 6ms/step\n",
            "Epoch 16/20\n",
            "4/4 - 0s - loss: 0.6606 - accuracy: 0.8400 - val_loss: 4.8134 - val_accuracy: 0.2703 - 24ms/epoch - 6ms/step\n",
            "Epoch 17/20\n",
            "4/4 - 0s - loss: 0.5867 - accuracy: 0.8750 - val_loss: 4.8223 - val_accuracy: 0.2432 - 25ms/epoch - 6ms/step\n",
            "Epoch 18/20\n",
            "4/4 - 0s - loss: 0.5316 - accuracy: 0.8800 - val_loss: 4.8442 - val_accuracy: 0.2973 - 25ms/epoch - 6ms/step\n",
            "Epoch 19/20\n",
            "4/4 - 0s - loss: 0.4896 - accuracy: 0.8900 - val_loss: 4.8495 - val_accuracy: 0.2973 - 42ms/epoch - 11ms/step\n",
            "Epoch 20/20\n",
            "4/4 - 0s - loss: 0.4372 - accuracy: 0.9000 - val_loss: 4.8190 - val_accuracy: 0.2973 - 21ms/epoch - 5ms/step\n",
            "seconds= 0.9997646808624268\n"
          ]
        }
      ]
    }
  ]
}