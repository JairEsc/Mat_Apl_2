{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNp298Ik7Jcyvsys0VfKgdA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JairEsc/Mat_Apl_2/blob/main/Biomate_NN_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IklufuqUwcpX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estructura de los datos."
      ],
      "metadata": {
        "id": "MpFOG--QxVDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consideramos un caso general, una base con datos de frecuencias de especies, cada observación de dimensión $k$, y supongamos que tenemos $n$ observaciones.\n",
        "\n",
        "El output busca ser la clasificación en una de $d$ categorías, definidas ya sea por ciudad o localización-clima (pero de un sólo tipo).\n"
      ],
      "metadata": {
        "id": "GznOeGsWxYfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos de ejemplo"
      ],
      "metadata": {
        "id": "NrrajEuRytBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"Dataset_w_tags.csv\")\n",
        "df.head()\n",
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)###El ajuste depende de este shuffle*****"
      ],
      "metadata": {
        "id": "30vL3CcXxUUE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zSWbW5vz3PI",
        "outputId": "82494b3b-beea-489e-b752-6559969167da"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(237, 513)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se tienen 237 observaciones, cada una es una muestra en una \"localización\".\n",
        "Por renglón, se tienen frecuencias de \"bichos\" de 510 \"dominant taxa\".\n",
        "\n",
        "En este caso, $k=510$, $n=237$."
      ],
      "metadata": {
        "id": "20gcA30JzhrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytags=df['Tag']\n",
        "print(ytags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I84se6Sw-Mdt",
        "outputId": "0108c166-38d7-4ac5-b07d-bf32db6a9d51"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "219    Temperate forests_0\n",
            "144       Dry grasslands_3\n",
            "148               Boreal_5\n",
            "233         Cold forests_3\n",
            "97           Dry forests_0\n",
            "              ...         \n",
            "55          Cold forests_6\n",
            "89           Dry forests_0\n",
            "80           Dry forests_0\n",
            "61          Cold forests_6\n",
            "222    Temperate forests_0\n",
            "Name: Tag, Length: 237, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytags"
      ],
      "metadata": {
        "id": "_n1a5c4A1-5_",
        "outputId": "ff69fa44-f9bb-4db4-95e6-f78ca43d95af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "219    Temperate forests_0\n",
              "144       Dry grasslands_3\n",
              "148               Boreal_5\n",
              "233         Cold forests_3\n",
              "97           Dry forests_0\n",
              "              ...         \n",
              "55          Cold forests_6\n",
              "89           Dry forests_0\n",
              "80           Dry forests_0\n",
              "61          Cold forests_6\n",
              "222    Temperate forests_0\n",
              "Name: Tag, Length: 237, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "_,idx = np.unique(ytags,return_inverse=True)"
      ],
      "metadata": {
        "id": "E6fYhQo7BNGu"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados los datos con su respectiva clasificación. (En el ejemplo $d=12$)"
      ],
      "metadata": {
        "id": "6mk01dMO3f12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(idx,bins=37)\n",
        "plt.show()#Mala representatividad de clases."
      ],
      "metadata": {
        "id": "QVlF0yPp2YOY",
        "outputId": "20238eee-0d75-4907-9fc6-e18e04bed12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición del modelo."
      ],
      "metadata": {
        "id": "fOP0O0MV3pmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partición de datos"
      ],
      "metadata": {
        "id": "JydTuMKmF2t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "X_total=df.drop(columns=['Tag','Dominant_taxa_ID/ID_Environmental'])\n",
        "Y_total=to_categorical(idx)"
      ],
      "metadata": {
        "id": "rrhUqdDM4cVL"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_total[0:200]\n",
        "Y_train=Y_total[0:200]"
      ],
      "metadata": {
        "id": "O2iYyd0mGEIW"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "k,n=X_train.shape\n",
        "n=n#-indice, -tag\n",
        "print(k,n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueLx_pz_GAe4",
        "outputId": "c0b9cc66-c674-471a-b4da-9fa97cb64763"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (n,)#=n\n",
        "output_shape=len(np.unique(ytags))"
      ],
      "metadata": {
        "id": "RrB-qCBDB1LX"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "from keras import models\n"
      ],
      "metadata": {
        "id": "XVlSzWd23fCO"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capas, neuronas, funciones de activación, loss."
      ],
      "metadata": {
        "id": "rlhbU_ZwNh_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.InputLayer(input_shape=(n,), name='Input_Layer'))#Obligatoria\n",
        "model.add(layers.Dense(10, activation='relu'))# Numero de capas ocultas: Opcional\n",
        "model.add(layers.Dense(10, activation='relu'))# Numero de neuronas en cada capa: Opcional\n",
        "model.add(layers.Dense(37, activation='Softmax', name='Output_Layer'))#Obligatoria\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "import time\n",
        "tic = time.time()\n",
        "\n",
        "model.fit(x = X_train, \n",
        "           y = Y_train, \n",
        "          validation_data=[X_total[200:], Y_total[200:]],\n",
        "          batch_size=50,\n",
        "           epochs=200,\n",
        "           verbose=2,shuffle=True)\n",
        "\n",
        "print('seconds=', time.time()-tic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ntg-BtqwqpQ",
        "outputId": "40b2e755-3312-445b-8b31-26395dcc408c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                5120      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                110       \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 37)                407       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,637\n",
            "Trainable params: 5,637\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "4/4 - 1s - loss: 10.6835 - accuracy: 0.0200 - val_loss: 7.5658 - val_accuracy: 0.0270 - 1s/epoch - 267ms/step\n",
            "Epoch 2/200\n",
            "4/4 - 0s - loss: 6.3449 - accuracy: 0.0300 - val_loss: 5.7665 - val_accuracy: 0.0000e+00 - 142ms/epoch - 36ms/step\n",
            "Epoch 3/200\n",
            "4/4 - 0s - loss: 4.7748 - accuracy: 0.0200 - val_loss: 4.9277 - val_accuracy: 0.0000e+00 - 160ms/epoch - 40ms/step\n",
            "Epoch 4/200\n",
            "4/4 - 0s - loss: 4.2081 - accuracy: 0.0250 - val_loss: 4.4308 - val_accuracy: 0.0000e+00 - 164ms/epoch - 41ms/step\n",
            "Epoch 5/200\n",
            "4/4 - 0s - loss: 3.9237 - accuracy: 0.0300 - val_loss: 4.0726 - val_accuracy: 0.0270 - 106ms/epoch - 26ms/step\n",
            "Epoch 6/200\n",
            "4/4 - 0s - loss: 3.7431 - accuracy: 0.0550 - val_loss: 3.8585 - val_accuracy: 0.0541 - 43ms/epoch - 11ms/step\n",
            "Epoch 7/200\n",
            "4/4 - 0s - loss: 3.6534 - accuracy: 0.1000 - val_loss: 3.7185 - val_accuracy: 0.0811 - 92ms/epoch - 23ms/step\n",
            "Epoch 8/200\n",
            "4/4 - 0s - loss: 3.5872 - accuracy: 0.1050 - val_loss: 3.6588 - val_accuracy: 0.1081 - 83ms/epoch - 21ms/step\n",
            "Epoch 9/200\n",
            "4/4 - 0s - loss: 3.5200 - accuracy: 0.1100 - val_loss: 3.6212 - val_accuracy: 0.1351 - 29ms/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "4/4 - 0s - loss: 3.4717 - accuracy: 0.1250 - val_loss: 3.5785 - val_accuracy: 0.1622 - 32ms/epoch - 8ms/step\n",
            "Epoch 11/200\n",
            "4/4 - 0s - loss: 3.4307 - accuracy: 0.1450 - val_loss: 3.5380 - val_accuracy: 0.1892 - 32ms/epoch - 8ms/step\n",
            "Epoch 12/200\n",
            "4/4 - 0s - loss: 3.3928 - accuracy: 0.1750 - val_loss: 3.5051 - val_accuracy: 0.2162 - 29ms/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "4/4 - 0s - loss: 3.3627 - accuracy: 0.2100 - val_loss: 3.4919 - val_accuracy: 0.2432 - 30ms/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "4/4 - 0s - loss: 3.3349 - accuracy: 0.2150 - val_loss: 3.4722 - val_accuracy: 0.2162 - 31ms/epoch - 8ms/step\n",
            "Epoch 15/200\n",
            "4/4 - 0s - loss: 3.3028 - accuracy: 0.2050 - val_loss: 3.4487 - val_accuracy: 0.2162 - 54ms/epoch - 14ms/step\n",
            "Epoch 16/200\n",
            "4/4 - 0s - loss: 3.2721 - accuracy: 0.2000 - val_loss: 3.4315 - val_accuracy: 0.2162 - 35ms/epoch - 9ms/step\n",
            "Epoch 17/200\n",
            "4/4 - 0s - loss: 3.2499 - accuracy: 0.2100 - val_loss: 3.4153 - val_accuracy: 0.2703 - 31ms/epoch - 8ms/step\n",
            "Epoch 18/200\n",
            "4/4 - 0s - loss: 3.2224 - accuracy: 0.2350 - val_loss: 3.4068 - val_accuracy: 0.3243 - 31ms/epoch - 8ms/step\n",
            "Epoch 19/200\n",
            "4/4 - 0s - loss: 3.1979 - accuracy: 0.2350 - val_loss: 3.3989 - val_accuracy: 0.3243 - 31ms/epoch - 8ms/step\n",
            "Epoch 20/200\n",
            "4/4 - 0s - loss: 3.1733 - accuracy: 0.2500 - val_loss: 3.3930 - val_accuracy: 0.3243 - 31ms/epoch - 8ms/step\n",
            "Epoch 21/200\n",
            "4/4 - 0s - loss: 3.1467 - accuracy: 0.2600 - val_loss: 3.3861 - val_accuracy: 0.3243 - 50ms/epoch - 13ms/step\n",
            "Epoch 22/200\n",
            "4/4 - 0s - loss: 3.1241 - accuracy: 0.2600 - val_loss: 3.3656 - val_accuracy: 0.3243 - 31ms/epoch - 8ms/step\n",
            "Epoch 23/200\n",
            "4/4 - 0s - loss: 3.0953 - accuracy: 0.2700 - val_loss: 3.3494 - val_accuracy: 0.3243 - 49ms/epoch - 12ms/step\n",
            "Epoch 24/200\n",
            "4/4 - 0s - loss: 3.0678 - accuracy: 0.2550 - val_loss: 3.3297 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "4/4 - 0s - loss: 3.0390 - accuracy: 0.2600 - val_loss: 3.3138 - val_accuracy: 0.2973 - 30ms/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "4/4 - 0s - loss: 3.0126 - accuracy: 0.2800 - val_loss: 3.3010 - val_accuracy: 0.2973 - 30ms/epoch - 8ms/step\n",
            "Epoch 27/200\n",
            "4/4 - 0s - loss: 2.9861 - accuracy: 0.3000 - val_loss: 3.2889 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "4/4 - 0s - loss: 2.9610 - accuracy: 0.3100 - val_loss: 3.2797 - val_accuracy: 0.3243 - 30ms/epoch - 8ms/step\n",
            "Epoch 29/200\n",
            "4/4 - 0s - loss: 2.9368 - accuracy: 0.3100 - val_loss: 3.2678 - val_accuracy: 0.2973 - 32ms/epoch - 8ms/step\n",
            "Epoch 30/200\n",
            "4/4 - 0s - loss: 2.9156 - accuracy: 0.3150 - val_loss: 3.2622 - val_accuracy: 0.2973 - 51ms/epoch - 13ms/step\n",
            "Epoch 31/200\n",
            "4/4 - 0s - loss: 2.8882 - accuracy: 0.3100 - val_loss: 3.2551 - val_accuracy: 0.2973 - 32ms/epoch - 8ms/step\n",
            "Epoch 32/200\n",
            "4/4 - 0s - loss: 2.8677 - accuracy: 0.3150 - val_loss: 3.2474 - val_accuracy: 0.2973 - 36ms/epoch - 9ms/step\n",
            "Epoch 33/200\n",
            "4/4 - 0s - loss: 2.8420 - accuracy: 0.3300 - val_loss: 3.2478 - val_accuracy: 0.2973 - 36ms/epoch - 9ms/step\n",
            "Epoch 34/200\n",
            "4/4 - 0s - loss: 2.8172 - accuracy: 0.3550 - val_loss: 3.2425 - val_accuracy: 0.2973 - 34ms/epoch - 8ms/step\n",
            "Epoch 35/200\n",
            "4/4 - 0s - loss: 2.7906 - accuracy: 0.3500 - val_loss: 3.2379 - val_accuracy: 0.2973 - 33ms/epoch - 8ms/step\n",
            "Epoch 36/200\n",
            "4/4 - 0s - loss: 2.7665 - accuracy: 0.3600 - val_loss: 3.2348 - val_accuracy: 0.2973 - 31ms/epoch - 8ms/step\n",
            "Epoch 37/200\n",
            "4/4 - 0s - loss: 2.7415 - accuracy: 0.3550 - val_loss: 3.2335 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "4/4 - 0s - loss: 2.7205 - accuracy: 0.3550 - val_loss: 3.2346 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "4/4 - 0s - loss: 2.6977 - accuracy: 0.3600 - val_loss: 3.2304 - val_accuracy: 0.2973 - 33ms/epoch - 8ms/step\n",
            "Epoch 40/200\n",
            "4/4 - 0s - loss: 2.6736 - accuracy: 0.3750 - val_loss: 3.2422 - val_accuracy: 0.2703 - 29ms/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "4/4 - 0s - loss: 2.6509 - accuracy: 0.3650 - val_loss: 3.2540 - val_accuracy: 0.2973 - 31ms/epoch - 8ms/step\n",
            "Epoch 42/200\n",
            "4/4 - 0s - loss: 2.6252 - accuracy: 0.3750 - val_loss: 3.2561 - val_accuracy: 0.2703 - 31ms/epoch - 8ms/step\n",
            "Epoch 43/200\n",
            "4/4 - 0s - loss: 2.6058 - accuracy: 0.3700 - val_loss: 3.2612 - val_accuracy: 0.2703 - 29ms/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "4/4 - 0s - loss: 2.5788 - accuracy: 0.3800 - val_loss: 3.2831 - val_accuracy: 0.2703 - 30ms/epoch - 8ms/step\n",
            "Epoch 45/200\n",
            "4/4 - 0s - loss: 2.5567 - accuracy: 0.3800 - val_loss: 3.3007 - val_accuracy: 0.2973 - 36ms/epoch - 9ms/step\n",
            "Epoch 46/200\n",
            "4/4 - 0s - loss: 2.5365 - accuracy: 0.3700 - val_loss: 3.3181 - val_accuracy: 0.2973 - 39ms/epoch - 10ms/step\n",
            "Epoch 47/200\n",
            "4/4 - 0s - loss: 2.5114 - accuracy: 0.3750 - val_loss: 3.3201 - val_accuracy: 0.2973 - 31ms/epoch - 8ms/step\n",
            "Epoch 48/200\n",
            "4/4 - 0s - loss: 2.4938 - accuracy: 0.3650 - val_loss: 3.3338 - val_accuracy: 0.2973 - 29ms/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "4/4 - 0s - loss: 2.4725 - accuracy: 0.3500 - val_loss: 3.3494 - val_accuracy: 0.2432 - 30ms/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "4/4 - 0s - loss: 2.4493 - accuracy: 0.3400 - val_loss: 3.3715 - val_accuracy: 0.2162 - 31ms/epoch - 8ms/step\n",
            "Epoch 51/200\n",
            "4/4 - 0s - loss: 2.4280 - accuracy: 0.3350 - val_loss: 3.3685 - val_accuracy: 0.2162 - 31ms/epoch - 8ms/step\n",
            "Epoch 52/200\n",
            "4/4 - 0s - loss: 2.4047 - accuracy: 0.3250 - val_loss: 3.3650 - val_accuracy: 0.1892 - 29ms/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "4/4 - 0s - loss: 2.3811 - accuracy: 0.3150 - val_loss: 3.3459 - val_accuracy: 0.1892 - 33ms/epoch - 8ms/step\n",
            "Epoch 54/200\n",
            "4/4 - 0s - loss: 2.3557 - accuracy: 0.3350 - val_loss: 3.3606 - val_accuracy: 0.1892 - 35ms/epoch - 9ms/step\n",
            "Epoch 55/200\n",
            "4/4 - 0s - loss: 2.3325 - accuracy: 0.3300 - val_loss: 3.3837 - val_accuracy: 0.1892 - 34ms/epoch - 9ms/step\n",
            "Epoch 56/200\n",
            "4/4 - 0s - loss: 2.3046 - accuracy: 0.3300 - val_loss: 3.4263 - val_accuracy: 0.1351 - 32ms/epoch - 8ms/step\n",
            "Epoch 57/200\n",
            "4/4 - 0s - loss: 2.2737 - accuracy: 0.3250 - val_loss: 3.4467 - val_accuracy: 0.1081 - 30ms/epoch - 8ms/step\n",
            "Epoch 58/200\n",
            "4/4 - 0s - loss: 2.2451 - accuracy: 0.3250 - val_loss: 3.4731 - val_accuracy: 0.1081 - 31ms/epoch - 8ms/step\n",
            "Epoch 59/200\n",
            "4/4 - 0s - loss: 2.2156 - accuracy: 0.3050 - val_loss: 3.4658 - val_accuracy: 0.1351 - 32ms/epoch - 8ms/step\n",
            "Epoch 60/200\n",
            "4/4 - 0s - loss: 2.1873 - accuracy: 0.3150 - val_loss: 3.4695 - val_accuracy: 0.1351 - 33ms/epoch - 8ms/step\n",
            "Epoch 61/200\n",
            "4/4 - 0s - loss: 2.1599 - accuracy: 0.3100 - val_loss: 3.4631 - val_accuracy: 0.1081 - 48ms/epoch - 12ms/step\n",
            "Epoch 62/200\n",
            "4/4 - 0s - loss: 2.1360 - accuracy: 0.3150 - val_loss: 3.4281 - val_accuracy: 0.1081 - 30ms/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "4/4 - 0s - loss: 2.1051 - accuracy: 0.3100 - val_loss: 3.4328 - val_accuracy: 0.1081 - 33ms/epoch - 8ms/step\n",
            "Epoch 64/200\n",
            "4/4 - 0s - loss: 2.0792 - accuracy: 0.3100 - val_loss: 3.4152 - val_accuracy: 0.1081 - 31ms/epoch - 8ms/step\n",
            "Epoch 65/200\n",
            "4/4 - 0s - loss: 2.0476 - accuracy: 0.3150 - val_loss: 3.4099 - val_accuracy: 0.1081 - 29ms/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "4/4 - 0s - loss: 2.0242 - accuracy: 0.3050 - val_loss: 3.4032 - val_accuracy: 0.1081 - 51ms/epoch - 13ms/step\n",
            "Epoch 67/200\n",
            "4/4 - 0s - loss: 1.9948 - accuracy: 0.3150 - val_loss: 3.4145 - val_accuracy: 0.1081 - 35ms/epoch - 9ms/step\n",
            "Epoch 68/200\n",
            "4/4 - 0s - loss: 1.9667 - accuracy: 0.3250 - val_loss: 3.4231 - val_accuracy: 0.1081 - 30ms/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "4/4 - 0s - loss: 1.9382 - accuracy: 0.3250 - val_loss: 3.4108 - val_accuracy: 0.1081 - 30ms/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "4/4 - 0s - loss: 1.9064 - accuracy: 0.3250 - val_loss: 3.3458 - val_accuracy: 0.0811 - 53ms/epoch - 13ms/step\n",
            "Epoch 71/200\n",
            "4/4 - 0s - loss: 1.8696 - accuracy: 0.3450 - val_loss: 3.3309 - val_accuracy: 0.0811 - 30ms/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "4/4 - 0s - loss: 1.8375 - accuracy: 0.3500 - val_loss: 3.3326 - val_accuracy: 0.0811 - 31ms/epoch - 8ms/step\n",
            "Epoch 73/200\n",
            "4/4 - 0s - loss: 1.8073 - accuracy: 0.3550 - val_loss: 3.3201 - val_accuracy: 0.0811 - 30ms/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "4/4 - 0s - loss: 1.7681 - accuracy: 0.3600 - val_loss: 3.2603 - val_accuracy: 0.0811 - 31ms/epoch - 8ms/step\n",
            "Epoch 75/200\n",
            "4/4 - 0s - loss: 1.7316 - accuracy: 0.3600 - val_loss: 3.1923 - val_accuracy: 0.0811 - 30ms/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "4/4 - 0s - loss: 1.6917 - accuracy: 0.3550 - val_loss: 3.1225 - val_accuracy: 0.1081 - 50ms/epoch - 12ms/step\n",
            "Epoch 77/200\n",
            "4/4 - 0s - loss: 1.6465 - accuracy: 0.3850 - val_loss: 3.0781 - val_accuracy: 0.1622 - 51ms/epoch - 13ms/step\n",
            "Epoch 78/200\n",
            "4/4 - 0s - loss: 1.6039 - accuracy: 0.5150 - val_loss: 3.0404 - val_accuracy: 0.3784 - 34ms/epoch - 8ms/step\n",
            "Epoch 79/200\n",
            "4/4 - 0s - loss: 1.5570 - accuracy: 0.5900 - val_loss: 3.0280 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 80/200\n",
            "4/4 - 0s - loss: 1.5111 - accuracy: 0.6000 - val_loss: 3.0037 - val_accuracy: 0.4324 - 39ms/epoch - 10ms/step\n",
            "Epoch 81/200\n",
            "4/4 - 0s - loss: 1.4560 - accuracy: 0.6000 - val_loss: 2.9737 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 82/200\n",
            "4/4 - 0s - loss: 1.4223 - accuracy: 0.6050 - val_loss: 3.0117 - val_accuracy: 0.4324 - 30ms/epoch - 8ms/step\n",
            "Epoch 83/200\n",
            "4/4 - 0s - loss: 1.3760 - accuracy: 0.6200 - val_loss: 3.0582 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "4/4 - 0s - loss: 1.3490 - accuracy: 0.6300 - val_loss: 3.0868 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "4/4 - 0s - loss: 1.3262 - accuracy: 0.6300 - val_loss: 3.0784 - val_accuracy: 0.4324 - 34ms/epoch - 8ms/step\n",
            "Epoch 86/200\n",
            "4/4 - 0s - loss: 1.3086 - accuracy: 0.6300 - val_loss: 3.0801 - val_accuracy: 0.4054 - 29ms/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "4/4 - 0s - loss: 1.2921 - accuracy: 0.6200 - val_loss: 3.1010 - val_accuracy: 0.4054 - 40ms/epoch - 10ms/step\n",
            "Epoch 88/200\n",
            "4/4 - 0s - loss: 1.2755 - accuracy: 0.6250 - val_loss: 3.1072 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 89/200\n",
            "4/4 - 0s - loss: 1.2628 - accuracy: 0.6250 - val_loss: 3.1135 - val_accuracy: 0.4054 - 30ms/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "4/4 - 0s - loss: 1.2446 - accuracy: 0.6250 - val_loss: 3.1156 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 91/200\n",
            "4/4 - 0s - loss: 1.2367 - accuracy: 0.6300 - val_loss: 3.0920 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 92/200\n",
            "4/4 - 0s - loss: 1.2213 - accuracy: 0.6300 - val_loss: 3.1222 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 93/200\n",
            "4/4 - 0s - loss: 1.2044 - accuracy: 0.6300 - val_loss: 3.1645 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 94/200\n",
            "4/4 - 0s - loss: 1.1941 - accuracy: 0.6300 - val_loss: 3.1838 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 95/200\n",
            "4/4 - 0s - loss: 1.1794 - accuracy: 0.6300 - val_loss: 3.2041 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 96/200\n",
            "4/4 - 0s - loss: 1.1689 - accuracy: 0.6300 - val_loss: 3.1804 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 97/200\n",
            "4/4 - 0s - loss: 1.1598 - accuracy: 0.6350 - val_loss: 3.1894 - val_accuracy: 0.4054 - 30ms/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "4/4 - 0s - loss: 1.1499 - accuracy: 0.6350 - val_loss: 3.1944 - val_accuracy: 0.4054 - 30ms/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "4/4 - 0s - loss: 1.1386 - accuracy: 0.6350 - val_loss: 3.2088 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 100/200\n",
            "4/4 - 0s - loss: 1.1284 - accuracy: 0.6350 - val_loss: 3.2121 - val_accuracy: 0.4054 - 49ms/epoch - 12ms/step\n",
            "Epoch 101/200\n",
            "4/4 - 0s - loss: 1.1207 - accuracy: 0.6400 - val_loss: 3.2375 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 102/200\n",
            "4/4 - 0s - loss: 1.1125 - accuracy: 0.6400 - val_loss: 3.2560 - val_accuracy: 0.4054 - 52ms/epoch - 13ms/step\n",
            "Epoch 103/200\n",
            "4/4 - 0s - loss: 1.1020 - accuracy: 0.6450 - val_loss: 3.2593 - val_accuracy: 0.4054 - 32ms/epoch - 8ms/step\n",
            "Epoch 104/200\n",
            "4/4 - 0s - loss: 1.0924 - accuracy: 0.6450 - val_loss: 3.2403 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 105/200\n",
            "4/4 - 0s - loss: 1.0873 - accuracy: 0.6450 - val_loss: 3.2438 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 106/200\n",
            "4/4 - 0s - loss: 1.0805 - accuracy: 0.6450 - val_loss: 3.2689 - val_accuracy: 0.4054 - 32ms/epoch - 8ms/step\n",
            "Epoch 107/200\n",
            "4/4 - 0s - loss: 1.0806 - accuracy: 0.6500 - val_loss: 3.3564 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 108/200\n",
            "4/4 - 0s - loss: 1.0602 - accuracy: 0.6600 - val_loss: 3.3545 - val_accuracy: 0.4054 - 28ms/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "4/4 - 0s - loss: 1.0530 - accuracy: 0.6600 - val_loss: 3.3135 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 110/200\n",
            "4/4 - 0s - loss: 1.0374 - accuracy: 0.6550 - val_loss: 3.3717 - val_accuracy: 0.4054 - 34ms/epoch - 9ms/step\n",
            "Epoch 111/200\n",
            "4/4 - 0s - loss: 1.0316 - accuracy: 0.6550 - val_loss: 3.3910 - val_accuracy: 0.4054 - 52ms/epoch - 13ms/step\n",
            "Epoch 112/200\n",
            "4/4 - 0s - loss: 1.0213 - accuracy: 0.6550 - val_loss: 3.3841 - val_accuracy: 0.4054 - 29ms/epoch - 7ms/step\n",
            "Epoch 113/200\n",
            "4/4 - 0s - loss: 1.0072 - accuracy: 0.6600 - val_loss: 3.4441 - val_accuracy: 0.4054 - 38ms/epoch - 9ms/step\n",
            "Epoch 114/200\n",
            "4/4 - 0s - loss: 0.9980 - accuracy: 0.6650 - val_loss: 3.4753 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 115/200\n",
            "4/4 - 0s - loss: 0.9861 - accuracy: 0.6700 - val_loss: 3.4679 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 116/200\n",
            "4/4 - 0s - loss: 0.9757 - accuracy: 0.6700 - val_loss: 3.5206 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "Epoch 117/200\n",
            "4/4 - 0s - loss: 0.9677 - accuracy: 0.6750 - val_loss: 3.5544 - val_accuracy: 0.4054 - 50ms/epoch - 13ms/step\n",
            "Epoch 118/200\n",
            "4/4 - 0s - loss: 0.9620 - accuracy: 0.6750 - val_loss: 3.6003 - val_accuracy: 0.4054 - 30ms/epoch - 7ms/step\n",
            "Epoch 119/200\n",
            "4/4 - 0s - loss: 0.9514 - accuracy: 0.6700 - val_loss: 3.5627 - val_accuracy: 0.4054 - 52ms/epoch - 13ms/step\n",
            "Epoch 120/200\n",
            "4/4 - 0s - loss: 0.9459 - accuracy: 0.6750 - val_loss: 3.5828 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 121/200\n",
            "4/4 - 0s - loss: 0.9407 - accuracy: 0.6700 - val_loss: 3.6232 - val_accuracy: 0.4054 - 35ms/epoch - 9ms/step\n",
            "Epoch 122/200\n",
            "4/4 - 0s - loss: 0.9354 - accuracy: 0.6700 - val_loss: 3.6109 - val_accuracy: 0.4054 - 34ms/epoch - 8ms/step\n",
            "Epoch 123/200\n",
            "4/4 - 0s - loss: 0.9306 - accuracy: 0.6800 - val_loss: 3.6139 - val_accuracy: 0.4054 - 32ms/epoch - 8ms/step\n",
            "Epoch 124/200\n",
            "4/4 - 0s - loss: 0.9228 - accuracy: 0.6800 - val_loss: 3.6413 - val_accuracy: 0.4054 - 54ms/epoch - 14ms/step\n",
            "Epoch 125/200\n",
            "4/4 - 0s - loss: 0.9214 - accuracy: 0.6800 - val_loss: 3.6259 - val_accuracy: 0.4054 - 37ms/epoch - 9ms/step\n",
            "Epoch 126/200\n",
            "4/4 - 0s - loss: 0.9170 - accuracy: 0.6800 - val_loss: 3.7024 - val_accuracy: 0.4054 - 38ms/epoch - 9ms/step\n",
            "Epoch 127/200\n",
            "4/4 - 0s - loss: 0.9145 - accuracy: 0.6800 - val_loss: 3.6681 - val_accuracy: 0.4054 - 38ms/epoch - 10ms/step\n",
            "Epoch 128/200\n",
            "4/4 - 0s - loss: 0.9078 - accuracy: 0.6800 - val_loss: 3.6855 - val_accuracy: 0.4054 - 35ms/epoch - 9ms/step\n",
            "Epoch 129/200\n",
            "4/4 - 0s - loss: 0.8988 - accuracy: 0.6800 - val_loss: 3.7041 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 130/200\n",
            "4/4 - 0s - loss: 0.8929 - accuracy: 0.6850 - val_loss: 3.7528 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 131/200\n",
            "4/4 - 0s - loss: 0.8870 - accuracy: 0.6850 - val_loss: 3.7385 - val_accuracy: 0.4324 - 34ms/epoch - 8ms/step\n",
            "Epoch 132/200\n",
            "4/4 - 0s - loss: 0.8824 - accuracy: 0.6850 - val_loss: 3.7534 - val_accuracy: 0.4324 - 49ms/epoch - 12ms/step\n",
            "Epoch 133/200\n",
            "4/4 - 0s - loss: 0.8759 - accuracy: 0.6850 - val_loss: 3.8107 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 134/200\n",
            "4/4 - 0s - loss: 0.8662 - accuracy: 0.6850 - val_loss: 3.8424 - val_accuracy: 0.4324 - 32ms/epoch - 8ms/step\n",
            "Epoch 135/200\n",
            "4/4 - 0s - loss: 0.8566 - accuracy: 0.6900 - val_loss: 3.8372 - val_accuracy: 0.4324 - 35ms/epoch - 9ms/step\n",
            "Epoch 136/200\n",
            "4/4 - 0s - loss: 0.8506 - accuracy: 0.6900 - val_loss: 3.8578 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 137/200\n",
            "4/4 - 0s - loss: 0.8469 - accuracy: 0.6900 - val_loss: 3.8371 - val_accuracy: 0.4324 - 32ms/epoch - 8ms/step\n",
            "Epoch 138/200\n",
            "4/4 - 0s - loss: 0.8476 - accuracy: 0.6900 - val_loss: 3.9399 - val_accuracy: 0.4324 - 30ms/epoch - 8ms/step\n",
            "Epoch 139/200\n",
            "4/4 - 0s - loss: 0.8397 - accuracy: 0.6950 - val_loss: 3.8896 - val_accuracy: 0.4324 - 40ms/epoch - 10ms/step\n",
            "Epoch 140/200\n",
            "4/4 - 0s - loss: 0.8353 - accuracy: 0.6950 - val_loss: 4.0482 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 141/200\n",
            "4/4 - 0s - loss: 0.8378 - accuracy: 0.7050 - val_loss: 4.0206 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 142/200\n",
            "4/4 - 0s - loss: 0.8179 - accuracy: 0.6950 - val_loss: 3.9666 - val_accuracy: 0.4324 - 30ms/epoch - 8ms/step\n",
            "Epoch 143/200\n",
            "4/4 - 0s - loss: 0.8124 - accuracy: 0.7050 - val_loss: 4.0368 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 144/200\n",
            "4/4 - 0s - loss: 0.8056 - accuracy: 0.7250 - val_loss: 4.0428 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 145/200\n",
            "4/4 - 0s - loss: 0.7976 - accuracy: 0.7400 - val_loss: 4.0915 - val_accuracy: 0.4324 - 36ms/epoch - 9ms/step\n",
            "Epoch 146/200\n",
            "4/4 - 0s - loss: 0.7918 - accuracy: 0.7400 - val_loss: 4.1254 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 147/200\n",
            "4/4 - 0s - loss: 0.7871 - accuracy: 0.7400 - val_loss: 4.1913 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 148/200\n",
            "4/4 - 0s - loss: 0.7792 - accuracy: 0.7400 - val_loss: 4.2158 - val_accuracy: 0.4595 - 31ms/epoch - 8ms/step\n",
            "Epoch 149/200\n",
            "4/4 - 0s - loss: 0.7749 - accuracy: 0.7500 - val_loss: 4.2227 - val_accuracy: 0.4595 - 33ms/epoch - 8ms/step\n",
            "Epoch 150/200\n",
            "4/4 - 0s - loss: 0.7696 - accuracy: 0.7500 - val_loss: 4.2720 - val_accuracy: 0.4595 - 36ms/epoch - 9ms/step\n",
            "Epoch 151/200\n",
            "4/4 - 0s - loss: 0.7646 - accuracy: 0.7500 - val_loss: 4.2501 - val_accuracy: 0.4595 - 30ms/epoch - 8ms/step\n",
            "Epoch 152/200\n",
            "4/4 - 0s - loss: 0.7614 - accuracy: 0.7500 - val_loss: 4.2852 - val_accuracy: 0.4595 - 33ms/epoch - 8ms/step\n",
            "Epoch 153/200\n",
            "4/4 - 0s - loss: 0.7581 - accuracy: 0.7550 - val_loss: 4.3489 - val_accuracy: 0.4595 - 31ms/epoch - 8ms/step\n",
            "Epoch 154/200\n",
            "4/4 - 0s - loss: 0.7520 - accuracy: 0.7550 - val_loss: 4.3340 - val_accuracy: 0.4595 - 32ms/epoch - 8ms/step\n",
            "Epoch 155/200\n",
            "4/4 - 0s - loss: 0.7470 - accuracy: 0.7700 - val_loss: 4.3459 - val_accuracy: 0.4595 - 37ms/epoch - 9ms/step\n",
            "Epoch 156/200\n",
            "4/4 - 0s - loss: 0.7420 - accuracy: 0.7650 - val_loss: 4.3851 - val_accuracy: 0.4595 - 30ms/epoch - 7ms/step\n",
            "Epoch 157/200\n",
            "4/4 - 0s - loss: 0.7395 - accuracy: 0.7650 - val_loss: 4.3946 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 158/200\n",
            "4/4 - 0s - loss: 0.7350 - accuracy: 0.7650 - val_loss: 4.4355 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 159/200\n",
            "4/4 - 0s - loss: 0.7285 - accuracy: 0.7700 - val_loss: 4.4781 - val_accuracy: 0.4595 - 29ms/epoch - 7ms/step\n",
            "Epoch 160/200\n",
            "4/4 - 0s - loss: 0.7251 - accuracy: 0.7650 - val_loss: 4.4693 - val_accuracy: 0.4595 - 34ms/epoch - 8ms/step\n",
            "Epoch 161/200\n",
            "4/4 - 0s - loss: 0.7168 - accuracy: 0.7700 - val_loss: 4.4883 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 162/200\n",
            "4/4 - 0s - loss: 0.7122 - accuracy: 0.7750 - val_loss: 4.5612 - val_accuracy: 0.4595 - 32ms/epoch - 8ms/step\n",
            "Epoch 163/200\n",
            "4/4 - 0s - loss: 0.7064 - accuracy: 0.7750 - val_loss: 4.5629 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 164/200\n",
            "4/4 - 0s - loss: 0.7016 - accuracy: 0.7700 - val_loss: 4.6008 - val_accuracy: 0.4324 - 34ms/epoch - 8ms/step\n",
            "Epoch 165/200\n",
            "4/4 - 0s - loss: 0.6975 - accuracy: 0.7700 - val_loss: 4.5803 - val_accuracy: 0.4324 - 37ms/epoch - 9ms/step\n",
            "Epoch 166/200\n",
            "4/4 - 0s - loss: 0.6940 - accuracy: 0.7700 - val_loss: 4.5932 - val_accuracy: 0.4324 - 35ms/epoch - 9ms/step\n",
            "Epoch 167/200\n",
            "4/4 - 0s - loss: 0.6887 - accuracy: 0.7750 - val_loss: 4.6614 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 168/200\n",
            "4/4 - 0s - loss: 0.6875 - accuracy: 0.7650 - val_loss: 4.6683 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 169/200\n",
            "4/4 - 0s - loss: 0.6830 - accuracy: 0.7800 - val_loss: 4.6536 - val_accuracy: 0.4324 - 35ms/epoch - 9ms/step\n",
            "Epoch 170/200\n",
            "4/4 - 0s - loss: 0.6772 - accuracy: 0.7850 - val_loss: 4.6915 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 171/200\n",
            "4/4 - 0s - loss: 0.6715 - accuracy: 0.7850 - val_loss: 4.6998 - val_accuracy: 0.4324 - 34ms/epoch - 9ms/step\n",
            "Epoch 172/200\n",
            "4/4 - 0s - loss: 0.6641 - accuracy: 0.7850 - val_loss: 4.7301 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 173/200\n",
            "4/4 - 0s - loss: 0.6582 - accuracy: 0.7950 - val_loss: 4.7660 - val_accuracy: 0.4324 - 35ms/epoch - 9ms/step\n",
            "Epoch 174/200\n",
            "4/4 - 0s - loss: 0.6543 - accuracy: 0.8000 - val_loss: 4.8123 - val_accuracy: 0.4595 - 32ms/epoch - 8ms/step\n",
            "Epoch 175/200\n",
            "4/4 - 0s - loss: 0.6485 - accuracy: 0.8000 - val_loss: 4.8346 - val_accuracy: 0.4595 - 28ms/epoch - 7ms/step\n",
            "Epoch 176/200\n",
            "4/4 - 0s - loss: 0.6423 - accuracy: 0.8000 - val_loss: 4.9152 - val_accuracy: 0.4324 - 36ms/epoch - 9ms/step\n",
            "Epoch 177/200\n",
            "4/4 - 0s - loss: 0.6375 - accuracy: 0.8050 - val_loss: 4.9034 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 178/200\n",
            "4/4 - 0s - loss: 0.6320 - accuracy: 0.8000 - val_loss: 4.8864 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 179/200\n",
            "4/4 - 0s - loss: 0.6304 - accuracy: 0.8100 - val_loss: 4.9372 - val_accuracy: 0.4324 - 30ms/epoch - 7ms/step\n",
            "Epoch 180/200\n",
            "4/4 - 0s - loss: 0.6253 - accuracy: 0.8000 - val_loss: 4.9664 - val_accuracy: 0.4324 - 38ms/epoch - 9ms/step\n",
            "Epoch 181/200\n",
            "4/4 - 0s - loss: 0.6229 - accuracy: 0.8050 - val_loss: 4.9734 - val_accuracy: 0.4054 - 34ms/epoch - 8ms/step\n",
            "Epoch 182/200\n",
            "4/4 - 0s - loss: 0.6175 - accuracy: 0.8050 - val_loss: 5.0064 - val_accuracy: 0.4054 - 35ms/epoch - 9ms/step\n",
            "Epoch 183/200\n",
            "4/4 - 0s - loss: 0.6141 - accuracy: 0.8150 - val_loss: 4.9811 - val_accuracy: 0.4324 - 29ms/epoch - 7ms/step\n",
            "Epoch 184/200\n",
            "4/4 - 0s - loss: 0.6107 - accuracy: 0.8050 - val_loss: 5.0561 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 185/200\n",
            "4/4 - 0s - loss: 0.6087 - accuracy: 0.8100 - val_loss: 5.0340 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 186/200\n",
            "4/4 - 0s - loss: 0.6043 - accuracy: 0.8100 - val_loss: 5.0590 - val_accuracy: 0.4324 - 42ms/epoch - 10ms/step\n",
            "Epoch 187/200\n",
            "4/4 - 0s - loss: 0.6016 - accuracy: 0.8150 - val_loss: 5.1389 - val_accuracy: 0.4324 - 33ms/epoch - 8ms/step\n",
            "Epoch 188/200\n",
            "4/4 - 0s - loss: 0.5984 - accuracy: 0.8050 - val_loss: 5.1434 - val_accuracy: 0.4324 - 49ms/epoch - 12ms/step\n",
            "Epoch 189/200\n",
            "4/4 - 0s - loss: 0.5955 - accuracy: 0.8100 - val_loss: 5.1216 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 190/200\n",
            "4/4 - 0s - loss: 0.5935 - accuracy: 0.8000 - val_loss: 5.1814 - val_accuracy: 0.4054 - 30ms/epoch - 8ms/step\n",
            "Epoch 191/200\n",
            "4/4 - 0s - loss: 0.5899 - accuracy: 0.8050 - val_loss: 5.1869 - val_accuracy: 0.4054 - 28ms/epoch - 7ms/step\n",
            "Epoch 192/200\n",
            "4/4 - 0s - loss: 0.5869 - accuracy: 0.8150 - val_loss: 5.2024 - val_accuracy: 0.4054 - 33ms/epoch - 8ms/step\n",
            "Epoch 193/200\n",
            "4/4 - 0s - loss: 0.5841 - accuracy: 0.8100 - val_loss: 5.2228 - val_accuracy: 0.4324 - 28ms/epoch - 7ms/step\n",
            "Epoch 194/200\n",
            "4/4 - 0s - loss: 0.5828 - accuracy: 0.8100 - val_loss: 5.2386 - val_accuracy: 0.4324 - 44ms/epoch - 11ms/step\n",
            "Epoch 195/200\n",
            "4/4 - 0s - loss: 0.5836 - accuracy: 0.8150 - val_loss: 5.2861 - val_accuracy: 0.4324 - 32ms/epoch - 8ms/step\n",
            "Epoch 196/200\n",
            "4/4 - 0s - loss: 0.5742 - accuracy: 0.8050 - val_loss: 5.2691 - val_accuracy: 0.4324 - 36ms/epoch - 9ms/step\n",
            "Epoch 197/200\n",
            "4/4 - 0s - loss: 0.5688 - accuracy: 0.8150 - val_loss: 5.2846 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 198/200\n",
            "4/4 - 0s - loss: 0.5669 - accuracy: 0.8200 - val_loss: 5.2860 - val_accuracy: 0.4324 - 47ms/epoch - 12ms/step\n",
            "Epoch 199/200\n",
            "4/4 - 0s - loss: 0.5631 - accuracy: 0.8200 - val_loss: 5.3274 - val_accuracy: 0.4324 - 31ms/epoch - 8ms/step\n",
            "Epoch 200/200\n",
            "4/4 - 0s - loss: 0.5618 - accuracy: 0.8150 - val_loss: 5.3562 - val_accuracy: 0.4054 - 31ms/epoch - 8ms/step\n",
            "seconds= 11.093770503997803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('primer_intento.h5')"
      ],
      "metadata": {
        "id": "qNN7Vb00PLUL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "test_predicted_labels = model.predict(X_total[200:])\n",
        "test_true_labels      = np.argmax(Y_total[200:],axis=1)\n",
        "test_predicted_labels = np.argmax(test_predicted_labels,axis=1)"
      ],
      "metadata": {
        "id": "Iek95NWhuTME",
        "outputId": "bcddac6e-1558-4f0d-bbb2-5bec7053e52c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segundo intento. Leave One Out Cross Validation Method."
      ],
      "metadata": {
        "id": "rYu2VOad4e2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sean $X_1,X_2,\\ldots, X_n$ las observaciones. \n",
        "Para cada $i\\in\\{1,2,\\ldots,n\\}$ se define una red $RN(i)$, que es entrenada con los datos \n",
        "$$X_{train}^{(i)}=\\{X\\}_{i=1}^n - \\{X_i\\}$$\n",
        "$$X_{val}^{(i)}=\\{X_i\\}$$\n",
        "\n",
        "\n",
        "Sea $Y_{pred}^{(i)}=RN(i)(X_i)$ la predicción del dato de entrenamiento.\n",
        "\n",
        "Para cada $i$, se obtiene un error $\\epsilon_i\\in\\{0,1\\}$.\n",
        "\n",
        "Definimos una precisión global como \n",
        "$$\\frac{1}{n}\\sum_{i=1}^n \\epsilon_i$$"
      ],
      "metadata": {
        "id": "pRGzMDUp4mj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "df = pd.read_csv(\"Dataset_w_tags.csv\")\n",
        "df.head()\n",
        "y_tags=df['Tag']\n",
        "df_X=df.drop(columns=['Tag','Dominant_taxa_ID/ID_Environmental'])\n",
        "_,idx_Total = np.unique(ytags,return_inverse=True)\n",
        "#from sklearn.utils import shuffle\n",
        "#df = shuffle(df)###El ajuste depende de este shuffle*****"
      ],
      "metadata": {
        "id": "PN3ik5Bk7dZB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size_fijo=10\n",
        "epochs_fijas=200\n",
        "def RN(i):#Recibe $i\\in\\{0,\\ldots,n\\}$\n",
        "    X_total=df_X\n",
        "    Y_total=idx_Total\n",
        "    X_train_i=X_total.drop(index=i)\n",
        "    Y_train_i=np.delete(idx_Total,i)\n",
        "    X_val=df_X[i]\n",
        "    Y_val=idx_Total[i]###Que sea de tipo categorical_keras\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(n,), name='Input_Layer'))#Obligatoria\n",
        "    model.add(layers.Dense(64, activation='relu'))# Numero de capas ocultas: Opcional\n",
        "    model.add(layers.Dense(32, activation='relu'))# Numero de neuronas en cada capa: Opcional\n",
        "    model.add(layers.Dense(37, activation='Softmax', name='Output_Layer'))#Obligatoria\n",
        "    model.summary()\n",
        "    model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "# This callback will stop the training when there is no improvement in\n",
        "# the loss for three consecutive epochs.\n",
        "    model.fit(x = X_train, \n",
        "            y = Y_train, \n",
        "            validation_data=[X_total[200:], Y_total[200:]],\n",
        "            batch_size=batch_size_fijo,\n",
        "            epochs=epochs_fijas,\n",
        "            verbose=2,shuffle=True,callbacks=[callback])\n",
        "    #Asumimos que se terminó de entrenar\n",
        "    test_predicted_labels = model.predict(X_val)\n",
        "    test_true_labels      = np.argmax(Y_val,axis=1)\n",
        "    test_predicted_labels = np.argmax(test_predicted_labels,axis=1)"
      ],
      "metadata": {
        "id": "9ZVOA4Cs5-Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4IJGHNU48GsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "id": "GmO-AIuA7Dxw",
        "outputId": "ff9d9b02-fdce-47ec-f538-b41d89d3d298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Dominant_taxa_ID/ID_Environmental  OTU_10  OTU_24  OTU_17316  OTU_124  \\\n",
              "1                                    2      94     324         51        0   \n",
              "2                                    3      92      82         22        3   \n",
              "3                                    4      58      79         23       27   \n",
              "4                                    5     306     214         12       15   \n",
              "5                                    6     288     502         12        6   \n",
              "..                                 ...     ...     ...        ...      ...   \n",
              "232                                233      20      18         21       32   \n",
              "233                                234     788     214         31       90   \n",
              "234                                235     791     156          5       88   \n",
              "235                                236     599     149         14       20   \n",
              "236                                237     103      20          0        3   \n",
              "\n",
              "     OTU_196  OTU_111  OTU_16  OTU_20  OTU_198  ...  OTU_7807  OTU_20167  \\\n",
              "1         26        1       1       4        9  ...         0          0   \n",
              "2         78        1       1       0        0  ...         0          0   \n",
              "3         49       11      63      14       94  ...         0          1   \n",
              "4         50       24      13       6       48  ...         1          0   \n",
              "5         48       12       1      14        7  ...         0          0   \n",
              "..       ...      ...     ...     ...      ...  ...       ...        ...   \n",
              "232       16        9      65      66        2  ...         0          3   \n",
              "233      194       40      10       1       15  ...         0          0   \n",
              "234       62       89      31       3       13  ...         0          0   \n",
              "235       43       61      22       3       24  ...         0          0   \n",
              "236       10       79       0       3        5  ...         0          0   \n",
              "\n",
              "     OTU_3763  OTU_998  OTU_618  OTU_961  OTU_3160  OTU_37856  OTU_882  \\\n",
              "1           0        0        0        0         0          0        0   \n",
              "2           0        0        2        0         0          0        0   \n",
              "3           1        0        6        2         0          2        1   \n",
              "4           3        0        3        0         0          1        0   \n",
              "5           0        0        0        0         0          0        0   \n",
              "..        ...      ...      ...      ...       ...        ...      ...   \n",
              "232         2        1        1        2         5          0        1   \n",
              "233         0        0        9        0         0          0        0   \n",
              "234         0        1        7        0         0          0        0   \n",
              "235         0        0        8        0         0          0        0   \n",
              "236         0        0       10        0         0          0        0   \n",
              "\n",
              "                     Tag  \n",
              "1               Boreal_9  \n",
              "2         Cold forests_1  \n",
              "3    Temperate forests_1  \n",
              "4           Grasslands_6  \n",
              "5           Grasslands_9  \n",
              "..                   ...  \n",
              "232        Dry forests_0  \n",
              "233       Cold forests_3  \n",
              "234       Cold forests_3  \n",
              "235       Cold forests_3  \n",
              "236         Shrublands_3  \n",
              "\n",
              "[236 rows x 513 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-447511b8-2f9d-47dd-9467-99d83d864af8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant_taxa_ID/ID_Environmental</th>\n",
              "      <th>OTU_10</th>\n",
              "      <th>OTU_24</th>\n",
              "      <th>OTU_17316</th>\n",
              "      <th>OTU_124</th>\n",
              "      <th>OTU_196</th>\n",
              "      <th>OTU_111</th>\n",
              "      <th>OTU_16</th>\n",
              "      <th>OTU_20</th>\n",
              "      <th>OTU_198</th>\n",
              "      <th>...</th>\n",
              "      <th>OTU_7807</th>\n",
              "      <th>OTU_20167</th>\n",
              "      <th>OTU_3763</th>\n",
              "      <th>OTU_998</th>\n",
              "      <th>OTU_618</th>\n",
              "      <th>OTU_961</th>\n",
              "      <th>OTU_3160</th>\n",
              "      <th>OTU_37856</th>\n",
              "      <th>OTU_882</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>324</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Boreal_9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>92</td>\n",
              "      <td>82</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Cold forests_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>79</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>49</td>\n",
              "      <td>11</td>\n",
              "      <td>63</td>\n",
              "      <td>14</td>\n",
              "      <td>94</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Temperate forests_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>306</td>\n",
              "      <td>214</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>50</td>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>48</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Grasslands_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>288</td>\n",
              "      <td>502</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>48</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Grasslands_9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>233</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>65</td>\n",
              "      <td>66</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Dry forests_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>234</td>\n",
              "      <td>788</td>\n",
              "      <td>214</td>\n",
              "      <td>31</td>\n",
              "      <td>90</td>\n",
              "      <td>194</td>\n",
              "      <td>40</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Cold forests_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>235</td>\n",
              "      <td>791</td>\n",
              "      <td>156</td>\n",
              "      <td>5</td>\n",
              "      <td>88</td>\n",
              "      <td>62</td>\n",
              "      <td>89</td>\n",
              "      <td>31</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Cold forests_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>236</td>\n",
              "      <td>599</td>\n",
              "      <td>149</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>43</td>\n",
              "      <td>61</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Cold forests_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>237</td>\n",
              "      <td>103</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Shrublands_3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>236 rows × 513 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-447511b8-2f9d-47dd-9467-99d83d864af8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-447511b8-2f9d-47dd-9467-99d83d864af8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-447511b8-2f9d-47dd-9467-99d83d864af8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}