{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/JairEsc/Mat_Apl_2/blob/main/ML_Neumonia.ipynb",
      "authorship_tag": "ABX9TyMoHsafL9KvWCpVWzayhbkS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JairEsc/Mat_Apl_2/blob/main/ML_Neumonia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "sRMsDCOglKo6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de cargar la base de Kaggle en Drive, y después de montar esta cuenta de Drive en Colab, tenemos acceso a las imágenes.\n",
        "\n",
        "Iniciamos el tratamiento de los datos haciendo un resize() para \"homogeneizar\" los tamaños de las imágenes."
      ],
      "metadata": {
        "id": "JotiNd0CH-3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "\n",
        "def loadImages(path):\n",
        "    # return array of images\n",
        "\n",
        "    imagesList = listdir(path)\n",
        "    loadedImages = []\n",
        "    for image in imagesList:\n",
        "        img = cv2.imread(path + image)\n",
        "        loadedImages.append(cv2.resize(img,(300,300)))\n",
        "\n",
        "    return np.array(loadedImages)\n",
        "\n",
        "path = \"/content/drive/MyDrive/test/NORMAL/\"\n",
        "\n",
        "# your images in an array\n",
        "test_normales = loadImages(\"/content/drive/MyDrive/test/NORMAL/\")\n",
        "test_neumonia= loadImages(\"/content/drive/MyDrive/test/PNEUMONIA/\")\n",
        "train_normales = loadImages(\"/content/drive/MyDrive/train/NORMAL/\")\n",
        "train_neumonia= loadImages(\"/content/drive/MyDrive/train/PNEUMONIA/\")\n",
        "val_normales = loadImages(\"/content/drive/MyDrive/val/NORMAL/\")\n",
        "val_neumonia= loadImages(\"/content/drive/MyDrive/val/PNEUMONIA/\")\n"
      ],
      "metadata": {
        "id": "_VBOcJtiliVz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenamos las imágenes de cada clase."
      ],
      "metadata": {
        "id": "xMvp33FiIUss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_test=np.concatenate((test_normales, test_neumonia), axis=0)\n",
        "full_train=np.concatenate((train_normales, train_neumonia), axis=0)\n",
        "full_val=np.concatenate((val_normales, val_neumonia), axis=0)\n"
      ],
      "metadata": {
        "id": "f035MoxB3y6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "convNN = models.Sequential()"
      ],
      "metadata": {
        "id": "0PEr28D54bzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos las etiquetas de cada clase que se usarán en el entrenamiento de la red."
      ],
      "metadata": {
        "id": "KCtZ7REeIaKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "train_labels = to_categorical(np.repeat((0,1),(len(train_normales),len(train_neumonia))))\n",
        "test_labels = to_categorical(np.repeat((0,1),(len(test_normales),len(test_neumonia))))\n",
        "val_labels = to_categorical(np.repeat((0,1),(len(val_normales),len(val_neumonia))))\n"
      ],
      "metadata": {
        "id": "LAY6lfGXDyQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos una función para describir la composición de una Red."
      ],
      "metadata": {
        "id": "jodkSAqQIgdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resumen(model=None):\n",
        "    '''\n",
        "    '''\n",
        "    header = '{:4} {:16} {:24} {:24} {:10}'.format('#', 'Layer Name','Layer Input Shape','Layer Output Shape','Parameters'\n",
        "    )\n",
        "    print('='*(len(header)))\n",
        "    print(header)\n",
        "    print('='*(len(header)))\n",
        "    count=0\n",
        "    count_trainable=0\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        count_trainable += layer.count_params() if layer.trainable else 0\n",
        "        input_shape = '{}'.format(layer.input_shape)\n",
        "        output_shape = '{}'.format(layer.output_shape)\n",
        "        str = '{:<4d} {:16} {:24} {:24} {:10}'.format(i,layer.name, input_shape, output_shape, layer.count_params())\n",
        "        print(str)\n",
        "        count += layer.count_params()\n",
        "    print('_'*(len(header)))\n",
        "    print('Total Parameters : ', count)\n",
        "    print('Total Trainable Parameters : ', count_trainable)\n",
        "    print('Total No-Trainable Parameters : ', count-count_trainable)\n",
        "    "
      ],
      "metadata": {
        "id": "RvOkaoKXTh7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este trabajo utilizaremos *EfficientNetB3* por tener una cantidad \"pequeña\" de parámetros."
      ],
      "metadata": {
        "id": "j7PwwwD3Ik3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import EfficientNetB3 \n",
        "\n",
        "Efficient = EfficientNetB3 (weights='imagenet',\n",
        "                  include_top=True,\n",
        "                  input_shape=(300, 300, 3))\n",
        "\n",
        "resumen(Efficient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsuzQxhvT3Xf",
        "outputId": "92feb853-eaa6-4249-ef08-7e015c937641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================================================\n",
            "#    Layer Name       Layer Input Shape        Layer Output Shape       Parameters\n",
            "==================================================================================\n",
            "0    input_1          [(None, 300, 300, 3)]    [(None, 300, 300, 3)]             0\n",
            "1    rescaling        (None, 300, 300, 3)      (None, 300, 300, 3)               0\n",
            "2    normalization    (None, 300, 300, 3)      (None, 300, 300, 3)               7\n",
            "3    tf.math.truediv  (None, 300, 300, 3)      (None, 300, 300, 3)               0\n",
            "4    stem_conv_pad    (None, 300, 300, 3)      (None, 301, 301, 3)               0\n",
            "5    stem_conv        (None, 301, 301, 3)      (None, 150, 150, 40)           1080\n",
            "6    stem_bn          (None, 150, 150, 40)     (None, 150, 150, 40)            160\n",
            "7    stem_activation  (None, 150, 150, 40)     (None, 150, 150, 40)              0\n",
            "8    block1a_dwconv   (None, 150, 150, 40)     (None, 150, 150, 40)            360\n",
            "9    block1a_bn       (None, 150, 150, 40)     (None, 150, 150, 40)            160\n",
            "10   block1a_activation (None, 150, 150, 40)     (None, 150, 150, 40)              0\n",
            "11   block1a_se_squeeze (None, 150, 150, 40)     (None, 40)                        0\n",
            "12   block1a_se_reshape (None, 40)               (None, 1, 1, 40)                  0\n",
            "13   block1a_se_reduce (None, 1, 1, 40)         (None, 1, 1, 10)                410\n",
            "14   block1a_se_expand (None, 1, 1, 10)         (None, 1, 1, 40)                440\n",
            "15   block1a_se_excite [(None, 150, 150, 40), (None, 1, 1, 40)] (None, 150, 150, 40)              0\n",
            "16   block1a_project_conv (None, 150, 150, 40)     (None, 150, 150, 24)            960\n",
            "17   block1a_project_bn (None, 150, 150, 24)     (None, 150, 150, 24)             96\n",
            "18   block1b_dwconv   (None, 150, 150, 24)     (None, 150, 150, 24)            216\n",
            "19   block1b_bn       (None, 150, 150, 24)     (None, 150, 150, 24)             96\n",
            "20   block1b_activation (None, 150, 150, 24)     (None, 150, 150, 24)              0\n",
            "21   block1b_se_squeeze (None, 150, 150, 24)     (None, 24)                        0\n",
            "22   block1b_se_reshape (None, 24)               (None, 1, 1, 24)                  0\n",
            "23   block1b_se_reduce (None, 1, 1, 24)         (None, 1, 1, 6)                 150\n",
            "24   block1b_se_expand (None, 1, 1, 6)          (None, 1, 1, 24)                168\n",
            "25   block1b_se_excite [(None, 150, 150, 24), (None, 1, 1, 24)] (None, 150, 150, 24)              0\n",
            "26   block1b_project_conv (None, 150, 150, 24)     (None, 150, 150, 24)            576\n",
            "27   block1b_project_bn (None, 150, 150, 24)     (None, 150, 150, 24)             96\n",
            "28   block1b_drop     (None, 150, 150, 24)     (None, 150, 150, 24)              0\n",
            "29   block1b_add      [(None, 150, 150, 24), (None, 150, 150, 24)] (None, 150, 150, 24)              0\n",
            "30   block2a_expand_conv (None, 150, 150, 24)     (None, 150, 150, 144)          3456\n",
            "31   block2a_expand_bn (None, 150, 150, 144)    (None, 150, 150, 144)           576\n",
            "32   block2a_expand_activation (None, 150, 150, 144)    (None, 150, 150, 144)             0\n",
            "33   block2a_dwconv_pad (None, 150, 150, 144)    (None, 151, 151, 144)             0\n",
            "34   block2a_dwconv   (None, 151, 151, 144)    (None, 75, 75, 144)            1296\n",
            "35   block2a_bn       (None, 75, 75, 144)      (None, 75, 75, 144)             576\n",
            "36   block2a_activation (None, 75, 75, 144)      (None, 75, 75, 144)               0\n",
            "37   block2a_se_squeeze (None, 75, 75, 144)      (None, 144)                       0\n",
            "38   block2a_se_reshape (None, 144)              (None, 1, 1, 144)                 0\n",
            "39   block2a_se_reduce (None, 1, 1, 144)        (None, 1, 1, 6)                 870\n",
            "40   block2a_se_expand (None, 1, 1, 6)          (None, 1, 1, 144)              1008\n",
            "41   block2a_se_excite [(None, 75, 75, 144), (None, 1, 1, 144)] (None, 75, 75, 144)               0\n",
            "42   block2a_project_conv (None, 75, 75, 144)      (None, 75, 75, 32)             4608\n",
            "43   block2a_project_bn (None, 75, 75, 32)       (None, 75, 75, 32)              128\n",
            "44   block2b_expand_conv (None, 75, 75, 32)       (None, 75, 75, 192)            6144\n",
            "45   block2b_expand_bn (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "46   block2b_expand_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "47   block2b_dwconv   (None, 75, 75, 192)      (None, 75, 75, 192)            1728\n",
            "48   block2b_bn       (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "49   block2b_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "50   block2b_se_squeeze (None, 75, 75, 192)      (None, 192)                       0\n",
            "51   block2b_se_reshape (None, 192)              (None, 1, 1, 192)                 0\n",
            "52   block2b_se_reduce (None, 1, 1, 192)        (None, 1, 1, 8)                1544\n",
            "53   block2b_se_expand (None, 1, 1, 8)          (None, 1, 1, 192)              1728\n",
            "54   block2b_se_excite [(None, 75, 75, 192), (None, 1, 1, 192)] (None, 75, 75, 192)               0\n",
            "55   block2b_project_conv (None, 75, 75, 192)      (None, 75, 75, 32)             6144\n",
            "56   block2b_project_bn (None, 75, 75, 32)       (None, 75, 75, 32)              128\n",
            "57   block2b_drop     (None, 75, 75, 32)       (None, 75, 75, 32)                0\n",
            "58   block2b_add      [(None, 75, 75, 32), (None, 75, 75, 32)] (None, 75, 75, 32)                0\n",
            "59   block2c_expand_conv (None, 75, 75, 32)       (None, 75, 75, 192)            6144\n",
            "60   block2c_expand_bn (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "61   block2c_expand_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "62   block2c_dwconv   (None, 75, 75, 192)      (None, 75, 75, 192)            1728\n",
            "63   block2c_bn       (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "64   block2c_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "65   block2c_se_squeeze (None, 75, 75, 192)      (None, 192)                       0\n",
            "66   block2c_se_reshape (None, 192)              (None, 1, 1, 192)                 0\n",
            "67   block2c_se_reduce (None, 1, 1, 192)        (None, 1, 1, 8)                1544\n",
            "68   block2c_se_expand (None, 1, 1, 8)          (None, 1, 1, 192)              1728\n",
            "69   block2c_se_excite [(None, 75, 75, 192), (None, 1, 1, 192)] (None, 75, 75, 192)               0\n",
            "70   block2c_project_conv (None, 75, 75, 192)      (None, 75, 75, 32)             6144\n",
            "71   block2c_project_bn (None, 75, 75, 32)       (None, 75, 75, 32)              128\n",
            "72   block2c_drop     (None, 75, 75, 32)       (None, 75, 75, 32)                0\n",
            "73   block2c_add      [(None, 75, 75, 32), (None, 75, 75, 32)] (None, 75, 75, 32)                0\n",
            "74   block3a_expand_conv (None, 75, 75, 32)       (None, 75, 75, 192)            6144\n",
            "75   block3a_expand_bn (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "76   block3a_expand_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "77   block3a_dwconv_pad (None, 75, 75, 192)      (None, 79, 79, 192)               0\n",
            "78   block3a_dwconv   (None, 79, 79, 192)      (None, 38, 38, 192)            4800\n",
            "79   block3a_bn       (None, 38, 38, 192)      (None, 38, 38, 192)             768\n",
            "80   block3a_activation (None, 38, 38, 192)      (None, 38, 38, 192)               0\n",
            "81   block3a_se_squeeze (None, 38, 38, 192)      (None, 192)                       0\n",
            "82   block3a_se_reshape (None, 192)              (None, 1, 1, 192)                 0\n",
            "83   block3a_se_reduce (None, 1, 1, 192)        (None, 1, 1, 8)                1544\n",
            "84   block3a_se_expand (None, 1, 1, 8)          (None, 1, 1, 192)              1728\n",
            "85   block3a_se_excite [(None, 38, 38, 192), (None, 1, 1, 192)] (None, 38, 38, 192)               0\n",
            "86   block3a_project_conv (None, 38, 38, 192)      (None, 38, 38, 48)             9216\n",
            "87   block3a_project_bn (None, 38, 38, 48)       (None, 38, 38, 48)              192\n",
            "88   block3b_expand_conv (None, 38, 38, 48)       (None, 38, 38, 288)           13824\n",
            "89   block3b_expand_bn (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "90   block3b_expand_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "91   block3b_dwconv   (None, 38, 38, 288)      (None, 38, 38, 288)            7200\n",
            "92   block3b_bn       (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "93   block3b_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "94   block3b_se_squeeze (None, 38, 38, 288)      (None, 288)                       0\n",
            "95   block3b_se_reshape (None, 288)              (None, 1, 1, 288)                 0\n",
            "96   block3b_se_reduce (None, 1, 1, 288)        (None, 1, 1, 12)               3468\n",
            "97   block3b_se_expand (None, 1, 1, 12)         (None, 1, 1, 288)              3744\n",
            "98   block3b_se_excite [(None, 38, 38, 288), (None, 1, 1, 288)] (None, 38, 38, 288)               0\n",
            "99   block3b_project_conv (None, 38, 38, 288)      (None, 38, 38, 48)            13824\n",
            "100  block3b_project_bn (None, 38, 38, 48)       (None, 38, 38, 48)              192\n",
            "101  block3b_drop     (None, 38, 38, 48)       (None, 38, 38, 48)                0\n",
            "102  block3b_add      [(None, 38, 38, 48), (None, 38, 38, 48)] (None, 38, 38, 48)                0\n",
            "103  block3c_expand_conv (None, 38, 38, 48)       (None, 38, 38, 288)           13824\n",
            "104  block3c_expand_bn (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "105  block3c_expand_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "106  block3c_dwconv   (None, 38, 38, 288)      (None, 38, 38, 288)            7200\n",
            "107  block3c_bn       (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "108  block3c_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "109  block3c_se_squeeze (None, 38, 38, 288)      (None, 288)                       0\n",
            "110  block3c_se_reshape (None, 288)              (None, 1, 1, 288)                 0\n",
            "111  block3c_se_reduce (None, 1, 1, 288)        (None, 1, 1, 12)               3468\n",
            "112  block3c_se_expand (None, 1, 1, 12)         (None, 1, 1, 288)              3744\n",
            "113  block3c_se_excite [(None, 38, 38, 288), (None, 1, 1, 288)] (None, 38, 38, 288)               0\n",
            "114  block3c_project_conv (None, 38, 38, 288)      (None, 38, 38, 48)            13824\n",
            "115  block3c_project_bn (None, 38, 38, 48)       (None, 38, 38, 48)              192\n",
            "116  block3c_drop     (None, 38, 38, 48)       (None, 38, 38, 48)                0\n",
            "117  block3c_add      [(None, 38, 38, 48), (None, 38, 38, 48)] (None, 38, 38, 48)                0\n",
            "118  block4a_expand_conv (None, 38, 38, 48)       (None, 38, 38, 288)           13824\n",
            "119  block4a_expand_bn (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "120  block4a_expand_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "121  block4a_dwconv_pad (None, 38, 38, 288)      (None, 39, 39, 288)               0\n",
            "122  block4a_dwconv   (None, 39, 39, 288)      (None, 19, 19, 288)            2592\n",
            "123  block4a_bn       (None, 19, 19, 288)      (None, 19, 19, 288)            1152\n",
            "124  block4a_activation (None, 19, 19, 288)      (None, 19, 19, 288)               0\n",
            "125  block4a_se_squeeze (None, 19, 19, 288)      (None, 288)                       0\n",
            "126  block4a_se_reshape (None, 288)              (None, 1, 1, 288)                 0\n",
            "127  block4a_se_reduce (None, 1, 1, 288)        (None, 1, 1, 12)               3468\n",
            "128  block4a_se_expand (None, 1, 1, 12)         (None, 1, 1, 288)              3744\n",
            "129  block4a_se_excite [(None, 19, 19, 288), (None, 1, 1, 288)] (None, 19, 19, 288)               0\n",
            "130  block4a_project_conv (None, 19, 19, 288)      (None, 19, 19, 96)            27648\n",
            "131  block4a_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "132  block4b_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "133  block4b_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "134  block4b_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "135  block4b_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)            5184\n",
            "136  block4b_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "137  block4b_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "138  block4b_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "139  block4b_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "140  block4b_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "141  block4b_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "142  block4b_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "143  block4b_project_conv (None, 19, 19, 576)      (None, 19, 19, 96)            55296\n",
            "144  block4b_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "145  block4b_drop     (None, 19, 19, 96)       (None, 19, 19, 96)                0\n",
            "146  block4b_add      [(None, 19, 19, 96), (None, 19, 19, 96)] (None, 19, 19, 96)                0\n",
            "147  block4c_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "148  block4c_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "149  block4c_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "150  block4c_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)            5184\n",
            "151  block4c_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "152  block4c_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "153  block4c_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "154  block4c_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "155  block4c_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "156  block4c_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "157  block4c_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "158  block4c_project_conv (None, 19, 19, 576)      (None, 19, 19, 96)            55296\n",
            "159  block4c_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "160  block4c_drop     (None, 19, 19, 96)       (None, 19, 19, 96)                0\n",
            "161  block4c_add      [(None, 19, 19, 96), (None, 19, 19, 96)] (None, 19, 19, 96)                0\n",
            "162  block4d_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "163  block4d_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "164  block4d_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "165  block4d_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)            5184\n",
            "166  block4d_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "167  block4d_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "168  block4d_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "169  block4d_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "170  block4d_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "171  block4d_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "172  block4d_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "173  block4d_project_conv (None, 19, 19, 576)      (None, 19, 19, 96)            55296\n",
            "174  block4d_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "175  block4d_drop     (None, 19, 19, 96)       (None, 19, 19, 96)                0\n",
            "176  block4d_add      [(None, 19, 19, 96), (None, 19, 19, 96)] (None, 19, 19, 96)                0\n",
            "177  block4e_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "178  block4e_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "179  block4e_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "180  block4e_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)            5184\n",
            "181  block4e_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "182  block4e_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "183  block4e_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "184  block4e_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "185  block4e_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "186  block4e_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "187  block4e_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "188  block4e_project_conv (None, 19, 19, 576)      (None, 19, 19, 96)            55296\n",
            "189  block4e_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "190  block4e_drop     (None, 19, 19, 96)       (None, 19, 19, 96)                0\n",
            "191  block4e_add      [(None, 19, 19, 96), (None, 19, 19, 96)] (None, 19, 19, 96)                0\n",
            "192  block5a_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "193  block5a_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "194  block5a_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "195  block5a_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)           14400\n",
            "196  block5a_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "197  block5a_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "198  block5a_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "199  block5a_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "200  block5a_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "201  block5a_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "202  block5a_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "203  block5a_project_conv (None, 19, 19, 576)      (None, 19, 19, 136)           78336\n",
            "204  block5a_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "205  block5b_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "206  block5b_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "207  block5b_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "208  block5b_dwconv   (None, 19, 19, 816)      (None, 19, 19, 816)           20400\n",
            "209  block5b_bn       (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "210  block5b_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "211  block5b_se_squeeze (None, 19, 19, 816)      (None, 816)                       0\n",
            "212  block5b_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "213  block5b_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "214  block5b_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "215  block5b_se_excite [(None, 19, 19, 816), (None, 1, 1, 816)] (None, 19, 19, 816)               0\n",
            "216  block5b_project_conv (None, 19, 19, 816)      (None, 19, 19, 136)          110976\n",
            "217  block5b_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "218  block5b_drop     (None, 19, 19, 136)      (None, 19, 19, 136)               0\n",
            "219  block5b_add      [(None, 19, 19, 136), (None, 19, 19, 136)] (None, 19, 19, 136)               0\n",
            "220  block5c_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "221  block5c_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "222  block5c_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "223  block5c_dwconv   (None, 19, 19, 816)      (None, 19, 19, 816)           20400\n",
            "224  block5c_bn       (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "225  block5c_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "226  block5c_se_squeeze (None, 19, 19, 816)      (None, 816)                       0\n",
            "227  block5c_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "228  block5c_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "229  block5c_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "230  block5c_se_excite [(None, 19, 19, 816), (None, 1, 1, 816)] (None, 19, 19, 816)               0\n",
            "231  block5c_project_conv (None, 19, 19, 816)      (None, 19, 19, 136)          110976\n",
            "232  block5c_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "233  block5c_drop     (None, 19, 19, 136)      (None, 19, 19, 136)               0\n",
            "234  block5c_add      [(None, 19, 19, 136), (None, 19, 19, 136)] (None, 19, 19, 136)               0\n",
            "235  block5d_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "236  block5d_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "237  block5d_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "238  block5d_dwconv   (None, 19, 19, 816)      (None, 19, 19, 816)           20400\n",
            "239  block5d_bn       (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "240  block5d_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "241  block5d_se_squeeze (None, 19, 19, 816)      (None, 816)                       0\n",
            "242  block5d_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "243  block5d_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "244  block5d_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "245  block5d_se_excite [(None, 19, 19, 816), (None, 1, 1, 816)] (None, 19, 19, 816)               0\n",
            "246  block5d_project_conv (None, 19, 19, 816)      (None, 19, 19, 136)          110976\n",
            "247  block5d_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "248  block5d_drop     (None, 19, 19, 136)      (None, 19, 19, 136)               0\n",
            "249  block5d_add      [(None, 19, 19, 136), (None, 19, 19, 136)] (None, 19, 19, 136)               0\n",
            "250  block5e_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "251  block5e_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "252  block5e_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "253  block5e_dwconv   (None, 19, 19, 816)      (None, 19, 19, 816)           20400\n",
            "254  block5e_bn       (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "255  block5e_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "256  block5e_se_squeeze (None, 19, 19, 816)      (None, 816)                       0\n",
            "257  block5e_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "258  block5e_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "259  block5e_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "260  block5e_se_excite [(None, 19, 19, 816), (None, 1, 1, 816)] (None, 19, 19, 816)               0\n",
            "261  block5e_project_conv (None, 19, 19, 816)      (None, 19, 19, 136)          110976\n",
            "262  block5e_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "263  block5e_drop     (None, 19, 19, 136)      (None, 19, 19, 136)               0\n",
            "264  block5e_add      [(None, 19, 19, 136), (None, 19, 19, 136)] (None, 19, 19, 136)               0\n",
            "265  block6a_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "266  block6a_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "267  block6a_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "268  block6a_dwconv_pad (None, 19, 19, 816)      (None, 23, 23, 816)               0\n",
            "269  block6a_dwconv   (None, 23, 23, 816)      (None, 10, 10, 816)           20400\n",
            "270  block6a_bn       (None, 10, 10, 816)      (None, 10, 10, 816)            3264\n",
            "271  block6a_activation (None, 10, 10, 816)      (None, 10, 10, 816)               0\n",
            "272  block6a_se_squeeze (None, 10, 10, 816)      (None, 816)                       0\n",
            "273  block6a_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "274  block6a_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "275  block6a_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "276  block6a_se_excite [(None, 10, 10, 816), (None, 1, 1, 816)] (None, 10, 10, 816)               0\n",
            "277  block6a_project_conv (None, 10, 10, 816)      (None, 10, 10, 232)          189312\n",
            "278  block6a_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "279  block6b_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "280  block6b_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "281  block6b_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "282  block6b_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "283  block6b_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "284  block6b_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "285  block6b_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "286  block6b_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "287  block6b_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "288  block6b_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "289  block6b_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "290  block6b_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "291  block6b_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "292  block6b_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "293  block6b_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "294  block6c_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "295  block6c_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "296  block6c_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "297  block6c_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "298  block6c_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "299  block6c_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "300  block6c_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "301  block6c_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "302  block6c_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "303  block6c_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "304  block6c_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "305  block6c_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "306  block6c_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "307  block6c_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "308  block6c_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "309  block6d_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "310  block6d_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "311  block6d_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "312  block6d_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "313  block6d_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "314  block6d_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "315  block6d_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "316  block6d_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "317  block6d_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "318  block6d_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "319  block6d_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "320  block6d_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "321  block6d_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "322  block6d_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "323  block6d_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "324  block6e_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "325  block6e_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "326  block6e_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "327  block6e_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "328  block6e_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "329  block6e_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "330  block6e_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "331  block6e_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "332  block6e_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "333  block6e_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "334  block6e_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "335  block6e_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "336  block6e_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "337  block6e_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "338  block6e_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "339  block6f_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "340  block6f_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "341  block6f_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "342  block6f_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "343  block6f_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "344  block6f_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "345  block6f_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "346  block6f_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "347  block6f_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "348  block6f_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "349  block6f_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "350  block6f_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "351  block6f_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "352  block6f_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "353  block6f_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "354  block7a_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "355  block7a_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "356  block7a_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "357  block7a_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          12528\n",
            "358  block7a_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "359  block7a_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "360  block7a_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "361  block7a_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "362  block7a_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "363  block7a_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "364  block7a_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "365  block7a_project_conv (None, 10, 10, 1392)     (None, 10, 10, 384)          534528\n",
            "366  block7a_project_bn (None, 10, 10, 384)      (None, 10, 10, 384)            1536\n",
            "367  block7b_expand_conv (None, 10, 10, 384)      (None, 10, 10, 2304)         884736\n",
            "368  block7b_expand_bn (None, 10, 10, 2304)     (None, 10, 10, 2304)           9216\n",
            "369  block7b_expand_activation (None, 10, 10, 2304)     (None, 10, 10, 2304)              0\n",
            "370  block7b_dwconv   (None, 10, 10, 2304)     (None, 10, 10, 2304)          20736\n",
            "371  block7b_bn       (None, 10, 10, 2304)     (None, 10, 10, 2304)           9216\n",
            "372  block7b_activation (None, 10, 10, 2304)     (None, 10, 10, 2304)              0\n",
            "373  block7b_se_squeeze (None, 10, 10, 2304)     (None, 2304)                      0\n",
            "374  block7b_se_reshape (None, 2304)             (None, 1, 1, 2304)                0\n",
            "375  block7b_se_reduce (None, 1, 1, 2304)       (None, 1, 1, 96)             221280\n",
            "376  block7b_se_expand (None, 1, 1, 96)         (None, 1, 1, 2304)           223488\n",
            "377  block7b_se_excite [(None, 10, 10, 2304), (None, 1, 1, 2304)] (None, 10, 10, 2304)              0\n",
            "378  block7b_project_conv (None, 10, 10, 2304)     (None, 10, 10, 384)          884736\n",
            "379  block7b_project_bn (None, 10, 10, 384)      (None, 10, 10, 384)            1536\n",
            "380  block7b_drop     (None, 10, 10, 384)      (None, 10, 10, 384)               0\n",
            "381  block7b_add      [(None, 10, 10, 384), (None, 10, 10, 384)] (None, 10, 10, 384)               0\n",
            "382  top_conv         (None, 10, 10, 384)      (None, 10, 10, 1536)         589824\n",
            "383  top_bn           (None, 10, 10, 1536)     (None, 10, 10, 1536)           6144\n",
            "384  top_activation   (None, 10, 10, 1536)     (None, 10, 10, 1536)              0\n",
            "385  avg_pool         (None, 10, 10, 1536)     (None, 1536)                      0\n",
            "386  top_dropout      (None, 1536)             (None, 1536)                      0\n",
            "387  predictions      (None, 1536)             (None, 1000)                1537000\n",
            "__________________________________________________________________________________\n",
            "Total Parameters :  12320535\n",
            "Total Trainable Parameters :  12320535\n",
            "Total No-Trainable Parameters :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que hay 12 millones de parámetros, y la red recibe un input de dimensiones (300,300,3). I.e. una imagen de 300$\\times$300 con 3 canales."
      ],
      "metadata": {
        "id": "aJKW2HxzIvQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos lo que será nuestra parte convolucional, definida por las primeras capas de EfficientNetB3."
      ],
      "metadata": {
        "id": "Wit4j3B1JBnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Efficient=None \n",
        "if Efficient != None:\n",
        "    del Efficient\n",
        "    \n",
        "from keras.applications import EfficientNetB3\n",
        "\n",
        "conv_base = EfficientNetB3(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(300, 300, 3))\n",
        "    \n",
        "resumen(conv_base)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TawCnxxufHpy",
        "outputId": "6e098648-ad02-4c70-c0bb-1efdea067b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================================================\n",
            "#    Layer Name       Layer Input Shape        Layer Output Shape       Parameters\n",
            "==================================================================================\n",
            "0    input_2          [(None, 300, 300, 3)]    [(None, 300, 300, 3)]             0\n",
            "1    rescaling_1      (None, 300, 300, 3)      (None, 300, 300, 3)               0\n",
            "2    normalization_1  (None, 300, 300, 3)      (None, 300, 300, 3)               7\n",
            "3    tf.math.truediv_1 (None, 300, 300, 3)      (None, 300, 300, 3)               0\n",
            "4    stem_conv_pad    (None, 300, 300, 3)      (None, 301, 301, 3)               0\n",
            "5    stem_conv        (None, 301, 301, 3)      (None, 150, 150, 40)           1080\n",
            "6    stem_bn          (None, 150, 150, 40)     (None, 150, 150, 40)            160\n",
            "7    stem_activation  (None, 150, 150, 40)     (None, 150, 150, 40)              0\n",
            "8    block1a_dwconv   (None, 150, 150, 40)     (None, 150, 150, 40)            360\n",
            "9    block1a_bn       (None, 150, 150, 40)     (None, 150, 150, 40)            160\n",
            "10   block1a_activation (None, 150, 150, 40)     (None, 150, 150, 40)              0\n",
            "11   block1a_se_squeeze (None, 150, 150, 40)     (None, 40)                        0\n",
            "12   block1a_se_reshape (None, 40)               (None, 1, 1, 40)                  0\n",
            "13   block1a_se_reduce (None, 1, 1, 40)         (None, 1, 1, 10)                410\n",
            "14   block1a_se_expand (None, 1, 1, 10)         (None, 1, 1, 40)                440\n",
            "15   block1a_se_excite [(None, 150, 150, 40), (None, 1, 1, 40)] (None, 150, 150, 40)              0\n",
            "16   block1a_project_conv (None, 150, 150, 40)     (None, 150, 150, 24)            960\n",
            "17   block1a_project_bn (None, 150, 150, 24)     (None, 150, 150, 24)             96\n",
            "18   block1b_dwconv   (None, 150, 150, 24)     (None, 150, 150, 24)            216\n",
            "19   block1b_bn       (None, 150, 150, 24)     (None, 150, 150, 24)             96\n",
            "20   block1b_activation (None, 150, 150, 24)     (None, 150, 150, 24)              0\n",
            "21   block1b_se_squeeze (None, 150, 150, 24)     (None, 24)                        0\n",
            "22   block1b_se_reshape (None, 24)               (None, 1, 1, 24)                  0\n",
            "23   block1b_se_reduce (None, 1, 1, 24)         (None, 1, 1, 6)                 150\n",
            "24   block1b_se_expand (None, 1, 1, 6)          (None, 1, 1, 24)                168\n",
            "25   block1b_se_excite [(None, 150, 150, 24), (None, 1, 1, 24)] (None, 150, 150, 24)              0\n",
            "26   block1b_project_conv (None, 150, 150, 24)     (None, 150, 150, 24)            576\n",
            "27   block1b_project_bn (None, 150, 150, 24)     (None, 150, 150, 24)             96\n",
            "28   block1b_drop     (None, 150, 150, 24)     (None, 150, 150, 24)              0\n",
            "29   block1b_add      [(None, 150, 150, 24), (None, 150, 150, 24)] (None, 150, 150, 24)              0\n",
            "30   block2a_expand_conv (None, 150, 150, 24)     (None, 150, 150, 144)          3456\n",
            "31   block2a_expand_bn (None, 150, 150, 144)    (None, 150, 150, 144)           576\n",
            "32   block2a_expand_activation (None, 150, 150, 144)    (None, 150, 150, 144)             0\n",
            "33   block2a_dwconv_pad (None, 150, 150, 144)    (None, 151, 151, 144)             0\n",
            "34   block2a_dwconv   (None, 151, 151, 144)    (None, 75, 75, 144)            1296\n",
            "35   block2a_bn       (None, 75, 75, 144)      (None, 75, 75, 144)             576\n",
            "36   block2a_activation (None, 75, 75, 144)      (None, 75, 75, 144)               0\n",
            "37   block2a_se_squeeze (None, 75, 75, 144)      (None, 144)                       0\n",
            "38   block2a_se_reshape (None, 144)              (None, 1, 1, 144)                 0\n",
            "39   block2a_se_reduce (None, 1, 1, 144)        (None, 1, 1, 6)                 870\n",
            "40   block2a_se_expand (None, 1, 1, 6)          (None, 1, 1, 144)              1008\n",
            "41   block2a_se_excite [(None, 75, 75, 144), (None, 1, 1, 144)] (None, 75, 75, 144)               0\n",
            "42   block2a_project_conv (None, 75, 75, 144)      (None, 75, 75, 32)             4608\n",
            "43   block2a_project_bn (None, 75, 75, 32)       (None, 75, 75, 32)              128\n",
            "44   block2b_expand_conv (None, 75, 75, 32)       (None, 75, 75, 192)            6144\n",
            "45   block2b_expand_bn (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "46   block2b_expand_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "47   block2b_dwconv   (None, 75, 75, 192)      (None, 75, 75, 192)            1728\n",
            "48   block2b_bn       (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "49   block2b_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "50   block2b_se_squeeze (None, 75, 75, 192)      (None, 192)                       0\n",
            "51   block2b_se_reshape (None, 192)              (None, 1, 1, 192)                 0\n",
            "52   block2b_se_reduce (None, 1, 1, 192)        (None, 1, 1, 8)                1544\n",
            "53   block2b_se_expand (None, 1, 1, 8)          (None, 1, 1, 192)              1728\n",
            "54   block2b_se_excite [(None, 75, 75, 192), (None, 1, 1, 192)] (None, 75, 75, 192)               0\n",
            "55   block2b_project_conv (None, 75, 75, 192)      (None, 75, 75, 32)             6144\n",
            "56   block2b_project_bn (None, 75, 75, 32)       (None, 75, 75, 32)              128\n",
            "57   block2b_drop     (None, 75, 75, 32)       (None, 75, 75, 32)                0\n",
            "58   block2b_add      [(None, 75, 75, 32), (None, 75, 75, 32)] (None, 75, 75, 32)                0\n",
            "59   block2c_expand_conv (None, 75, 75, 32)       (None, 75, 75, 192)            6144\n",
            "60   block2c_expand_bn (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "61   block2c_expand_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "62   block2c_dwconv   (None, 75, 75, 192)      (None, 75, 75, 192)            1728\n",
            "63   block2c_bn       (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "64   block2c_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "65   block2c_se_squeeze (None, 75, 75, 192)      (None, 192)                       0\n",
            "66   block2c_se_reshape (None, 192)              (None, 1, 1, 192)                 0\n",
            "67   block2c_se_reduce (None, 1, 1, 192)        (None, 1, 1, 8)                1544\n",
            "68   block2c_se_expand (None, 1, 1, 8)          (None, 1, 1, 192)              1728\n",
            "69   block2c_se_excite [(None, 75, 75, 192), (None, 1, 1, 192)] (None, 75, 75, 192)               0\n",
            "70   block2c_project_conv (None, 75, 75, 192)      (None, 75, 75, 32)             6144\n",
            "71   block2c_project_bn (None, 75, 75, 32)       (None, 75, 75, 32)              128\n",
            "72   block2c_drop     (None, 75, 75, 32)       (None, 75, 75, 32)                0\n",
            "73   block2c_add      [(None, 75, 75, 32), (None, 75, 75, 32)] (None, 75, 75, 32)                0\n",
            "74   block3a_expand_conv (None, 75, 75, 32)       (None, 75, 75, 192)            6144\n",
            "75   block3a_expand_bn (None, 75, 75, 192)      (None, 75, 75, 192)             768\n",
            "76   block3a_expand_activation (None, 75, 75, 192)      (None, 75, 75, 192)               0\n",
            "77   block3a_dwconv_pad (None, 75, 75, 192)      (None, 79, 79, 192)               0\n",
            "78   block3a_dwconv   (None, 79, 79, 192)      (None, 38, 38, 192)            4800\n",
            "79   block3a_bn       (None, 38, 38, 192)      (None, 38, 38, 192)             768\n",
            "80   block3a_activation (None, 38, 38, 192)      (None, 38, 38, 192)               0\n",
            "81   block3a_se_squeeze (None, 38, 38, 192)      (None, 192)                       0\n",
            "82   block3a_se_reshape (None, 192)              (None, 1, 1, 192)                 0\n",
            "83   block3a_se_reduce (None, 1, 1, 192)        (None, 1, 1, 8)                1544\n",
            "84   block3a_se_expand (None, 1, 1, 8)          (None, 1, 1, 192)              1728\n",
            "85   block3a_se_excite [(None, 38, 38, 192), (None, 1, 1, 192)] (None, 38, 38, 192)               0\n",
            "86   block3a_project_conv (None, 38, 38, 192)      (None, 38, 38, 48)             9216\n",
            "87   block3a_project_bn (None, 38, 38, 48)       (None, 38, 38, 48)              192\n",
            "88   block3b_expand_conv (None, 38, 38, 48)       (None, 38, 38, 288)           13824\n",
            "89   block3b_expand_bn (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "90   block3b_expand_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "91   block3b_dwconv   (None, 38, 38, 288)      (None, 38, 38, 288)            7200\n",
            "92   block3b_bn       (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "93   block3b_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "94   block3b_se_squeeze (None, 38, 38, 288)      (None, 288)                       0\n",
            "95   block3b_se_reshape (None, 288)              (None, 1, 1, 288)                 0\n",
            "96   block3b_se_reduce (None, 1, 1, 288)        (None, 1, 1, 12)               3468\n",
            "97   block3b_se_expand (None, 1, 1, 12)         (None, 1, 1, 288)              3744\n",
            "98   block3b_se_excite [(None, 38, 38, 288), (None, 1, 1, 288)] (None, 38, 38, 288)               0\n",
            "99   block3b_project_conv (None, 38, 38, 288)      (None, 38, 38, 48)            13824\n",
            "100  block3b_project_bn (None, 38, 38, 48)       (None, 38, 38, 48)              192\n",
            "101  block3b_drop     (None, 38, 38, 48)       (None, 38, 38, 48)                0\n",
            "102  block3b_add      [(None, 38, 38, 48), (None, 38, 38, 48)] (None, 38, 38, 48)                0\n",
            "103  block3c_expand_conv (None, 38, 38, 48)       (None, 38, 38, 288)           13824\n",
            "104  block3c_expand_bn (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "105  block3c_expand_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "106  block3c_dwconv   (None, 38, 38, 288)      (None, 38, 38, 288)            7200\n",
            "107  block3c_bn       (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "108  block3c_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "109  block3c_se_squeeze (None, 38, 38, 288)      (None, 288)                       0\n",
            "110  block3c_se_reshape (None, 288)              (None, 1, 1, 288)                 0\n",
            "111  block3c_se_reduce (None, 1, 1, 288)        (None, 1, 1, 12)               3468\n",
            "112  block3c_se_expand (None, 1, 1, 12)         (None, 1, 1, 288)              3744\n",
            "113  block3c_se_excite [(None, 38, 38, 288), (None, 1, 1, 288)] (None, 38, 38, 288)               0\n",
            "114  block3c_project_conv (None, 38, 38, 288)      (None, 38, 38, 48)            13824\n",
            "115  block3c_project_bn (None, 38, 38, 48)       (None, 38, 38, 48)              192\n",
            "116  block3c_drop     (None, 38, 38, 48)       (None, 38, 38, 48)                0\n",
            "117  block3c_add      [(None, 38, 38, 48), (None, 38, 38, 48)] (None, 38, 38, 48)                0\n",
            "118  block4a_expand_conv (None, 38, 38, 48)       (None, 38, 38, 288)           13824\n",
            "119  block4a_expand_bn (None, 38, 38, 288)      (None, 38, 38, 288)            1152\n",
            "120  block4a_expand_activation (None, 38, 38, 288)      (None, 38, 38, 288)               0\n",
            "121  block4a_dwconv_pad (None, 38, 38, 288)      (None, 39, 39, 288)               0\n",
            "122  block4a_dwconv   (None, 39, 39, 288)      (None, 19, 19, 288)            2592\n",
            "123  block4a_bn       (None, 19, 19, 288)      (None, 19, 19, 288)            1152\n",
            "124  block4a_activation (None, 19, 19, 288)      (None, 19, 19, 288)               0\n",
            "125  block4a_se_squeeze (None, 19, 19, 288)      (None, 288)                       0\n",
            "126  block4a_se_reshape (None, 288)              (None, 1, 1, 288)                 0\n",
            "127  block4a_se_reduce (None, 1, 1, 288)        (None, 1, 1, 12)               3468\n",
            "128  block4a_se_expand (None, 1, 1, 12)         (None, 1, 1, 288)              3744\n",
            "129  block4a_se_excite [(None, 19, 19, 288), (None, 1, 1, 288)] (None, 19, 19, 288)               0\n",
            "130  block4a_project_conv (None, 19, 19, 288)      (None, 19, 19, 96)            27648\n",
            "131  block4a_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "132  block4b_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "133  block4b_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "134  block4b_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "135  block4b_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)            5184\n",
            "136  block4b_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "137  block4b_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "138  block4b_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "139  block4b_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "140  block4b_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "141  block4b_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "142  block4b_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "143  block4b_project_conv (None, 19, 19, 576)      (None, 19, 19, 96)            55296\n",
            "144  block4b_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "145  block4b_drop     (None, 19, 19, 96)       (None, 19, 19, 96)                0\n",
            "146  block4b_add      [(None, 19, 19, 96), (None, 19, 19, 96)] (None, 19, 19, 96)                0\n",
            "147  block4c_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "148  block4c_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "149  block4c_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "150  block4c_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)            5184\n",
            "151  block4c_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "152  block4c_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "153  block4c_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "154  block4c_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "155  block4c_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "156  block4c_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "157  block4c_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "158  block4c_project_conv (None, 19, 19, 576)      (None, 19, 19, 96)            55296\n",
            "159  block4c_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "160  block4c_drop     (None, 19, 19, 96)       (None, 19, 19, 96)                0\n",
            "161  block4c_add      [(None, 19, 19, 96), (None, 19, 19, 96)] (None, 19, 19, 96)                0\n",
            "162  block4d_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "163  block4d_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "164  block4d_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "165  block4d_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)            5184\n",
            "166  block4d_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "167  block4d_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "168  block4d_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "169  block4d_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "170  block4d_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "171  block4d_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "172  block4d_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "173  block4d_project_conv (None, 19, 19, 576)      (None, 19, 19, 96)            55296\n",
            "174  block4d_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "175  block4d_drop     (None, 19, 19, 96)       (None, 19, 19, 96)                0\n",
            "176  block4d_add      [(None, 19, 19, 96), (None, 19, 19, 96)] (None, 19, 19, 96)                0\n",
            "177  block4e_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "178  block4e_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "179  block4e_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "180  block4e_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)            5184\n",
            "181  block4e_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "182  block4e_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "183  block4e_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "184  block4e_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "185  block4e_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "186  block4e_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "187  block4e_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "188  block4e_project_conv (None, 19, 19, 576)      (None, 19, 19, 96)            55296\n",
            "189  block4e_project_bn (None, 19, 19, 96)       (None, 19, 19, 96)              384\n",
            "190  block4e_drop     (None, 19, 19, 96)       (None, 19, 19, 96)                0\n",
            "191  block4e_add      [(None, 19, 19, 96), (None, 19, 19, 96)] (None, 19, 19, 96)                0\n",
            "192  block5a_expand_conv (None, 19, 19, 96)       (None, 19, 19, 576)           55296\n",
            "193  block5a_expand_bn (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "194  block5a_expand_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "195  block5a_dwconv   (None, 19, 19, 576)      (None, 19, 19, 576)           14400\n",
            "196  block5a_bn       (None, 19, 19, 576)      (None, 19, 19, 576)            2304\n",
            "197  block5a_activation (None, 19, 19, 576)      (None, 19, 19, 576)               0\n",
            "198  block5a_se_squeeze (None, 19, 19, 576)      (None, 576)                       0\n",
            "199  block5a_se_reshape (None, 576)              (None, 1, 1, 576)                 0\n",
            "200  block5a_se_reduce (None, 1, 1, 576)        (None, 1, 1, 24)              13848\n",
            "201  block5a_se_expand (None, 1, 1, 24)         (None, 1, 1, 576)             14400\n",
            "202  block5a_se_excite [(None, 19, 19, 576), (None, 1, 1, 576)] (None, 19, 19, 576)               0\n",
            "203  block5a_project_conv (None, 19, 19, 576)      (None, 19, 19, 136)           78336\n",
            "204  block5a_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "205  block5b_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "206  block5b_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "207  block5b_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "208  block5b_dwconv   (None, 19, 19, 816)      (None, 19, 19, 816)           20400\n",
            "209  block5b_bn       (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "210  block5b_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "211  block5b_se_squeeze (None, 19, 19, 816)      (None, 816)                       0\n",
            "212  block5b_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "213  block5b_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "214  block5b_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "215  block5b_se_excite [(None, 19, 19, 816), (None, 1, 1, 816)] (None, 19, 19, 816)               0\n",
            "216  block5b_project_conv (None, 19, 19, 816)      (None, 19, 19, 136)          110976\n",
            "217  block5b_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "218  block5b_drop     (None, 19, 19, 136)      (None, 19, 19, 136)               0\n",
            "219  block5b_add      [(None, 19, 19, 136), (None, 19, 19, 136)] (None, 19, 19, 136)               0\n",
            "220  block5c_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "221  block5c_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "222  block5c_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "223  block5c_dwconv   (None, 19, 19, 816)      (None, 19, 19, 816)           20400\n",
            "224  block5c_bn       (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "225  block5c_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "226  block5c_se_squeeze (None, 19, 19, 816)      (None, 816)                       0\n",
            "227  block5c_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "228  block5c_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "229  block5c_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "230  block5c_se_excite [(None, 19, 19, 816), (None, 1, 1, 816)] (None, 19, 19, 816)               0\n",
            "231  block5c_project_conv (None, 19, 19, 816)      (None, 19, 19, 136)          110976\n",
            "232  block5c_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "233  block5c_drop     (None, 19, 19, 136)      (None, 19, 19, 136)               0\n",
            "234  block5c_add      [(None, 19, 19, 136), (None, 19, 19, 136)] (None, 19, 19, 136)               0\n",
            "235  block5d_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "236  block5d_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "237  block5d_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "238  block5d_dwconv   (None, 19, 19, 816)      (None, 19, 19, 816)           20400\n",
            "239  block5d_bn       (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "240  block5d_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "241  block5d_se_squeeze (None, 19, 19, 816)      (None, 816)                       0\n",
            "242  block5d_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "243  block5d_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "244  block5d_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "245  block5d_se_excite [(None, 19, 19, 816), (None, 1, 1, 816)] (None, 19, 19, 816)               0\n",
            "246  block5d_project_conv (None, 19, 19, 816)      (None, 19, 19, 136)          110976\n",
            "247  block5d_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "248  block5d_drop     (None, 19, 19, 136)      (None, 19, 19, 136)               0\n",
            "249  block5d_add      [(None, 19, 19, 136), (None, 19, 19, 136)] (None, 19, 19, 136)               0\n",
            "250  block5e_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "251  block5e_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "252  block5e_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "253  block5e_dwconv   (None, 19, 19, 816)      (None, 19, 19, 816)           20400\n",
            "254  block5e_bn       (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "255  block5e_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "256  block5e_se_squeeze (None, 19, 19, 816)      (None, 816)                       0\n",
            "257  block5e_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "258  block5e_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "259  block5e_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "260  block5e_se_excite [(None, 19, 19, 816), (None, 1, 1, 816)] (None, 19, 19, 816)               0\n",
            "261  block5e_project_conv (None, 19, 19, 816)      (None, 19, 19, 136)          110976\n",
            "262  block5e_project_bn (None, 19, 19, 136)      (None, 19, 19, 136)             544\n",
            "263  block5e_drop     (None, 19, 19, 136)      (None, 19, 19, 136)               0\n",
            "264  block5e_add      [(None, 19, 19, 136), (None, 19, 19, 136)] (None, 19, 19, 136)               0\n",
            "265  block6a_expand_conv (None, 19, 19, 136)      (None, 19, 19, 816)          110976\n",
            "266  block6a_expand_bn (None, 19, 19, 816)      (None, 19, 19, 816)            3264\n",
            "267  block6a_expand_activation (None, 19, 19, 816)      (None, 19, 19, 816)               0\n",
            "268  block6a_dwconv_pad (None, 19, 19, 816)      (None, 23, 23, 816)               0\n",
            "269  block6a_dwconv   (None, 23, 23, 816)      (None, 10, 10, 816)           20400\n",
            "270  block6a_bn       (None, 10, 10, 816)      (None, 10, 10, 816)            3264\n",
            "271  block6a_activation (None, 10, 10, 816)      (None, 10, 10, 816)               0\n",
            "272  block6a_se_squeeze (None, 10, 10, 816)      (None, 816)                       0\n",
            "273  block6a_se_reshape (None, 816)              (None, 1, 1, 816)                 0\n",
            "274  block6a_se_reduce (None, 1, 1, 816)        (None, 1, 1, 34)              27778\n",
            "275  block6a_se_expand (None, 1, 1, 34)         (None, 1, 1, 816)             28560\n",
            "276  block6a_se_excite [(None, 10, 10, 816), (None, 1, 1, 816)] (None, 10, 10, 816)               0\n",
            "277  block6a_project_conv (None, 10, 10, 816)      (None, 10, 10, 232)          189312\n",
            "278  block6a_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "279  block6b_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "280  block6b_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "281  block6b_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "282  block6b_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "283  block6b_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "284  block6b_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "285  block6b_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "286  block6b_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "287  block6b_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "288  block6b_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "289  block6b_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "290  block6b_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "291  block6b_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "292  block6b_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "293  block6b_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "294  block6c_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "295  block6c_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "296  block6c_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "297  block6c_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "298  block6c_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "299  block6c_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "300  block6c_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "301  block6c_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "302  block6c_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "303  block6c_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "304  block6c_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "305  block6c_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "306  block6c_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "307  block6c_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "308  block6c_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "309  block6d_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "310  block6d_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "311  block6d_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "312  block6d_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "313  block6d_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "314  block6d_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "315  block6d_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "316  block6d_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "317  block6d_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "318  block6d_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "319  block6d_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "320  block6d_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "321  block6d_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "322  block6d_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "323  block6d_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "324  block6e_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "325  block6e_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "326  block6e_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "327  block6e_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "328  block6e_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "329  block6e_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "330  block6e_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "331  block6e_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "332  block6e_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "333  block6e_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "334  block6e_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "335  block6e_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "336  block6e_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "337  block6e_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "338  block6e_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "339  block6f_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "340  block6f_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "341  block6f_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "342  block6f_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          34800\n",
            "343  block6f_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "344  block6f_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "345  block6f_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "346  block6f_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "347  block6f_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "348  block6f_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "349  block6f_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "350  block6f_project_conv (None, 10, 10, 1392)     (None, 10, 10, 232)          322944\n",
            "351  block6f_project_bn (None, 10, 10, 232)      (None, 10, 10, 232)             928\n",
            "352  block6f_drop     (None, 10, 10, 232)      (None, 10, 10, 232)               0\n",
            "353  block6f_add      [(None, 10, 10, 232), (None, 10, 10, 232)] (None, 10, 10, 232)               0\n",
            "354  block7a_expand_conv (None, 10, 10, 232)      (None, 10, 10, 1392)         322944\n",
            "355  block7a_expand_bn (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "356  block7a_expand_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "357  block7a_dwconv   (None, 10, 10, 1392)     (None, 10, 10, 1392)          12528\n",
            "358  block7a_bn       (None, 10, 10, 1392)     (None, 10, 10, 1392)           5568\n",
            "359  block7a_activation (None, 10, 10, 1392)     (None, 10, 10, 1392)              0\n",
            "360  block7a_se_squeeze (None, 10, 10, 1392)     (None, 1392)                      0\n",
            "361  block7a_se_reshape (None, 1392)             (None, 1, 1, 1392)                0\n",
            "362  block7a_se_reduce (None, 1, 1, 1392)       (None, 1, 1, 58)              80794\n",
            "363  block7a_se_expand (None, 1, 1, 58)         (None, 1, 1, 1392)            82128\n",
            "364  block7a_se_excite [(None, 10, 10, 1392), (None, 1, 1, 1392)] (None, 10, 10, 1392)              0\n",
            "365  block7a_project_conv (None, 10, 10, 1392)     (None, 10, 10, 384)          534528\n",
            "366  block7a_project_bn (None, 10, 10, 384)      (None, 10, 10, 384)            1536\n",
            "367  block7b_expand_conv (None, 10, 10, 384)      (None, 10, 10, 2304)         884736\n",
            "368  block7b_expand_bn (None, 10, 10, 2304)     (None, 10, 10, 2304)           9216\n",
            "369  block7b_expand_activation (None, 10, 10, 2304)     (None, 10, 10, 2304)              0\n",
            "370  block7b_dwconv   (None, 10, 10, 2304)     (None, 10, 10, 2304)          20736\n",
            "371  block7b_bn       (None, 10, 10, 2304)     (None, 10, 10, 2304)           9216\n",
            "372  block7b_activation (None, 10, 10, 2304)     (None, 10, 10, 2304)              0\n",
            "373  block7b_se_squeeze (None, 10, 10, 2304)     (None, 2304)                      0\n",
            "374  block7b_se_reshape (None, 2304)             (None, 1, 1, 2304)                0\n",
            "375  block7b_se_reduce (None, 1, 1, 2304)       (None, 1, 1, 96)             221280\n",
            "376  block7b_se_expand (None, 1, 1, 96)         (None, 1, 1, 2304)           223488\n",
            "377  block7b_se_excite [(None, 10, 10, 2304), (None, 1, 1, 2304)] (None, 10, 10, 2304)              0\n",
            "378  block7b_project_conv (None, 10, 10, 2304)     (None, 10, 10, 384)          884736\n",
            "379  block7b_project_bn (None, 10, 10, 384)      (None, 10, 10, 384)            1536\n",
            "380  block7b_drop     (None, 10, 10, 384)      (None, 10, 10, 384)               0\n",
            "381  block7b_add      [(None, 10, 10, 384), (None, 10, 10, 384)] (None, 10, 10, 384)               0\n",
            "382  top_conv         (None, 10, 10, 384)      (None, 10, 10, 1536)         589824\n",
            "383  top_bn           (None, 10, 10, 1536)     (None, 10, 10, 1536)           6144\n",
            "384  top_activation   (None, 10, 10, 1536)     (None, 10, 10, 1536)              0\n",
            "__________________________________________________________________________________\n",
            "Total Parameters :  10783535\n",
            "Total Trainable Parameters :  10783535\n",
            "Total No-Trainable Parameters :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta parte tiene 10 millones de parámetros, y tiene un output de (10$\\times$10$\\times$1536)."
      ],
      "metadata": {
        "id": "8JmUBx7KJMBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se describe brevemente el procedimiento de entrenamiento.\n",
        "\n",
        "\n",
        "\n",
        "*   Congelamos las capas convolucionales heredadas por EfficientnetB3. De esta manera, los pesos de esta red se mantienen fijos, pues la transferencia de conocimientos supone que estos pesos extraen las características de las imagenes que se ingresan.\n",
        "*   Agregamos capas entranables a nuestro modelo. Agregamos capas convolucionales y densas, en este caso la primera capa debe recibir como input una imagen que coincida con la capa de salida de la parte convolucional heredada. Como se mencionó antes, de (10$\\times$10$\\times$1536). Pero esto lo hace automáticamente keras.\n",
        "*   Hasta ahora, tenemos una cantidad mucho menor de parámetros, que corresponden a los pesos de las capas que sí son entrenables. \n",
        "*   Procedemos a entrenar la red. De hecho, como las capas iniciales siguen congeladas, los únicos pesos que se modificarán, serán correspondientes a las capas que agregamos al final."
      ],
      "metadata": {
        "id": "TkIze8fiJYYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "model.add(conv_base)   \n"
      ],
      "metadata": {
        "id": "QpFDSGChB8qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))#4/2\n",
        "model.add(layers.Conv2D(filters     = 64, \n",
        "                        kernel_size = (3, 3), \n",
        "                        activation  = 'relu' ))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, \n",
        "                        activation='relu'))\n",
        "model.add(layers.Dense(64, \n",
        "                        activation='relu'))\n",
        "model.add(layers.Dense(2, \n",
        "                        activation='softmax'))"
      ],
      "metadata": {
        "id": "8hDE9RRfCF39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F954gBoyCNg7",
        "outputId": "841e0564-318c-4aae-a514-0f73924a7501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb3 (Functional)  (None, 10, 10, 1536)     10783535  \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 1536)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 3, 3, 64)          884800    \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 256)               147712    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,832,625\n",
            "Trainable params: 1,049,090\n",
            "Non-trainable params: 10,783,535\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notemos que solamente hay 1,049,090 parámetros entrenables. Procedemos a hacer el entrenamiento."
      ],
      "metadata": {
        "id": "ZFhNre2Qp6Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"nadam\",\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "M4_qXTAkCj20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "tic = time.time()\n",
        "\n",
        "model.fit(x = full_train, \n",
        "           y = train_labels, \n",
        "           epochs    =3,\n",
        "           batch_size=200,\n",
        "           verbose=2)\n",
        "\n",
        "print('seconds=', time.time()-tic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8DZA35xCrwG",
        "outputId": "460beca9-5e5f-4c1c-d0d8-317bb0c9b93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "27/27 - 59s - loss: 0.4309 - acc: 0.8401 - 59s/epoch - 2s/step\n",
            "Epoch 2/3\n",
            "27/27 - 33s - loss: 0.1348 - acc: 0.9477 - 33s/epoch - 1s/step\n",
            "Epoch 3/3\n",
            "27/27 - 33s - loss: 0.0850 - acc: 0.9701 - 33s/epoch - 1s/step\n",
            "seconds= 126.66766333580017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como vemos, tenemos un muy buen desempeño en muy poco tiempo, aprovechando el conocimiento de la red EfficientNetB3."
      ],
      "metadata": {
        "id": "u96x9dCqKto1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí, guardaremos nuestra red para reiniciar el entorno de ejecución y liberar memoria RAM."
      ],
      "metadata": {
        "id": "sCpHH48VDOWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('neumonia_dense_trained.h5')\n",
        "#from keras.models import load_model\n",
        "#model = load_model('neumonia_dense_trained.h5')"
      ],
      "metadata": {
        "id": "IaaNWKSODT5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, nos gustaría descongelar las capas heredadas de EfficientnetB3, de manera que se mejore el ajuste.\n",
        "Nota. Fue ejecutado en otro cuaderno de Colab"
      ],
      "metadata": {
        "id": "x8HeV7jvK4Fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.trainable=True\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYUzJkYNXEyE",
        "outputId": "542e718c-52c7-4ba8-acc2-e4e7b2bbe97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb3 (Functional)  (None, 10, 10, 1536)     10783535  \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 1536)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 64)          884800    \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               147712    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,832,625\n",
            "Trainable params: 11,745,322\n",
            "Non-trainable params: 87,303\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=['acc'])\n",
        "import time\n",
        "tic = time.time()\n",
        "\n",
        "model.fit(x = full_train, \n",
        "           y = train_labels, \n",
        "           epochs    =3,\n",
        "           batch_size=20,\n",
        "           verbose=2)\n",
        "\n",
        "print('seconds=', time.time()-tic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUcWgbd5XX9V",
        "outputId": "e105a0c9-26c1-4153-b630-f4dcdb1903a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "261/261 - 213s - loss: 0.1346 - acc: 0.9513 - 213s/epoch - 817ms/step\n",
            "Epoch 2/3\n",
            "261/261 - 182s - loss: 0.0648 - acc: 0.9757 - 182s/epoch - 699ms/step\n",
            "Epoch 3/3\n",
            "261/261 - 182s - loss: 0.0385 - acc: 0.9858 - 182s/epoch - 698ms/step\n",
            "seconds= 587.0070667266846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conseguimos un 98$\\%$ de accuracy con datos de entrenamiento."
      ],
      "metadata": {
        "id": "ogZ3EmPYhX2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Damos por finalizada la etapa de entrenamiento, veremos el desempeño con los datos de prueba."
      ],
      "metadata": {
        "id": "X6u6yMIVhj3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('neumonia_full_trained.h5')"
      ],
      "metadata": {
        "id": "1I74Jicph_vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "test_predicted_labels = model.predict(full_test)\n",
        "test_true_labels      = np.argmax(test_labels,axis=1)\n",
        "test_predicted_labels = np.argmax(test_predicted_labels,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeEJzyychwJa",
        "outputId": "3963b330-7a3b-4c32-f65e-3843ea883da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 7s 178ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix, precision_score, recall_score,roc_auc_score\n",
        "\n",
        "from sklearn.metrics import f1_score, cohen_kappa_score\n",
        "import seaborn as sns \n",
        "C = confusion_matrix(test_true_labels, test_predicted_labels)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "sns.set()\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "ax = sns.heatmap(C, cmap=cmap, square=True,\n",
        "                 annot=True, fmt='d', linewidths=.5)\n",
        "ax.set_title('Matriz de Confusión')\n",
        "plt.show()\n",
        "accuracy = accuracy_score(test_true_labels, test_predicted_labels)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(test_true_labels, test_predicted_labels,average='weighted')\n",
        "print('Precision: %f',precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(test_true_labels, test_predicted_labels,average='weighted')\n",
        "print('Recall: %f' , recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(test_true_labels, test_predicted_labels,average='weighted')\n",
        "print('F1 score: %f' % f1)\n",
        "print(\"AUC-ROC: \",roc_auc_score(test_true_labels,test_predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "rqpWml1ninSd",
        "outputId": "b2301f48-5f34-4e61-c985-856163a369e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x648 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.791667\n",
            "Precision: %f 0.84375\n",
            "Recall: %f 0.7916666666666666\n",
            "F1 score: 0.766484\n",
            "AUC-ROC:  0.7222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusión.\n",
        "\n",
        "Utilizamos la parte \"top\" de la EfficientNetB3, que fue entrenada con ImageNet. Congelamos estas capas heredadas y entrenamos únicamente las capas que agregamos a nuestro modelo.\n",
        "\n",
        "Notamos que el accuracy inicia con valores muy altos desde la primera epoca, lo que era de esperarse pues la transferencia de conocimiento era la intención de este trabajo.\n",
        "En la segunda parte, descongelamos todas las capas y utilizamos un optimizador de lento aprendizaje, pues se espera que nuestra red ya esté bien ajustada a los datos.\n",
        "\n",
        "Aunque llegamos a un $98\\%$ en la etapa de entrenamiento, y esto fue con muy poco entrenamiento, en la etapa de prueba apenas se llegó a $79\\%$. Esto podría ser por sobre-entrenamiento, lo cual es poco probable pues como mencionamos, fue muy poco entrenamiento."
      ],
      "metadata": {
        "id": "ZiftRMA6lUfj"
      }
    }
  ]
}